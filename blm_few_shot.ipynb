{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daac1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module_loader import ModuleLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e53271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module typing_extensions loaded successfully from /projects/academic/kjoseph/zijian/rag/lib/python3.9/site-packages/typing_extensions.py\n"
     ]
    }
   ],
   "source": [
    "loader = ModuleLoader(\"typing_extensions\", \"/projects/academic/kjoseph/zijian/rag/lib/python3.9/site-packages/typing_extensions.py\")\n",
    "typing_extensions = loader.load_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f8b6c9-c3b3-40e5-b867-30a6c85b3d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/rag/lib/python3.9/site-packages/transformers/utils/hub.py:125: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from human_annotator_with_hint import MySQLDataHandler, Annotation, ModelTraining, ActiveLearning,SimilaritySearchQuery,RAGLLMQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b9a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a8719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data = pd.read_csv('/projects/academic/kjoseph/zijian/blm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01f54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SimilaritySearchQuery(fastfit=False,simi_query=random_blm_data['modeling_text'].values[0:10].tolist(),texts=random_blm_data['modeling_text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54cb9c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.33it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 48.88it/s]\n"
     ]
    }
   ],
   "source": [
    "dist_score = test.calculate_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d95653a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Text</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>california released a 600-page reparations rep...</td>\n",
       "      <td>california released a 600-page reparations rep...</td>\n",
       "      <td>3.964277e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>california released a 600-page reparations rep...</td>\n",
       "      <td>it's time to stop trump's discriminatory anti-...</td>\n",
       "      <td>5.226083e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california released a 600-page reparations rep...</td>\n",
       "      <td>\"f‚Äî trump! f‚Äî white people!\"\\n\\n#blmkidnapping...</td>\n",
       "      <td>6.044470e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>california released a 600-page reparations rep...</td>\n",
       "      <td>#dearg8 it is time to break the vicious cycle ...</td>\n",
       "      <td>6.104068e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>california released a 600-page reparations rep...</td>\n",
       "      <td>üî±#topmeme award goes to @irrepressably for thi...</td>\n",
       "      <td>6.238652e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>details on the settlement that the city of lou...</td>\n",
       "      <td>details on the settlement that the city of lou...</td>\n",
       "      <td>4.957215e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>details on the settlement that the city of lou...</td>\n",
       "      <td>manhunt intensifies as authorities warn some r...</td>\n",
       "      <td>4.975649e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>details on the settlement that the city of lou...</td>\n",
       "      <td>.@slcmayor erin mendenhall is looking into fiv...</td>\n",
       "      <td>5.765610e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>details on the settlement that the city of lou...</td>\n",
       "      <td>this is one of the most beautiful, sad photos ...</td>\n",
       "      <td>6.103083e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>details on the settlement that the city of lou...</td>\n",
       "      <td>the possibility that the supreme court will ov...</td>\n",
       "      <td>6.166483e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>how do you describe today‚Äôs republican party?\\...</td>\n",
       "      <td>how do you describe today‚Äôs republican party?\\...</td>\n",
       "      <td>5.957785e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>how do you describe today‚Äôs republican party?\\...</td>\n",
       "      <td>ask the candidates how they would lift working...</td>\n",
       "      <td>7.775285e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how do you describe today‚Äôs republican party?\\...</td>\n",
       "      <td>donald trump has already said so much racist s...</td>\n",
       "      <td>8.732410e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>how do you describe today‚Äôs republican party?\\...</td>\n",
       "      <td>pa senate candidate outs himself as a total ra...</td>\n",
       "      <td>9.212234e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>i'll be joining my friend @seanhannity tonight...</td>\n",
       "      <td>i'll be joining my friend @seanhannity tonight...</td>\n",
       "      <td>4.775467e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>i'll be joining my friend @seanhannity tonight...</td>\n",
       "      <td>ive been thinking abt this for three days \\n\\n...</td>\n",
       "      <td>8.150777e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i'll be joining my friend @seanhannity tonight...</td>\n",
       "      <td>bedtime! cant wait for tomorrow; cohosting the...</td>\n",
       "      <td>8.286595e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i'll be joining my friend @seanhannity tonight...</td>\n",
       "      <td>there are bad takes, and then there are danger...</td>\n",
       "      <td>8.455081e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>judicial system's blessing of police use of ex...</td>\n",
       "      <td>judicial system's blessing of police use of ex...</td>\n",
       "      <td>7.156845e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>judicial system's blessing of police use of ex...</td>\n",
       "      <td>fuck yo #bluelivesmatter shit.\\n\\ncops choose ...</td>\n",
       "      <td>7.638995e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>judicial system's blessing of police use of ex...</td>\n",
       "      <td>teachers are ‚Äúlocal government workers‚Äù. we do...</td>\n",
       "      <td>7.907787e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>manhunt intensifies as authorities warn some r...</td>\n",
       "      <td>los angeles police said they have arrested a 2...</td>\n",
       "      <td>5.791704e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>melania is often described as useless but plea...</td>\n",
       "      <td>melania is often described as useless but plea...</td>\n",
       "      <td>1.017276e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>melania is often described as useless but plea...</td>\n",
       "      <td>by muddying the waters, you are destroying the...</td>\n",
       "      <td>8.742905e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>melania is often described as useless but plea...</td>\n",
       "      <td>white supremacist pleads guilty to killing a b...</td>\n",
       "      <td>8.827973e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>melania is often described as useless but plea...</td>\n",
       "      <td>wilmore: shouldn't dismiss #demdebate as \"bori...</td>\n",
       "      <td>9.001496e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>over 1 in 7 women, nearly 18 million, lived in...</td>\n",
       "      <td>over 1 in 7 women, nearly 18 million, lived in...</td>\n",
       "      <td>4.890947e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>over 1 in 7 women, nearly 18 million, lived in...</td>\n",
       "      <td>ending violence against women is everyone‚Äôs bu...</td>\n",
       "      <td>6.132743e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>over 1 in 7 women, nearly 18 million, lived in...</td>\n",
       "      <td>why we need a broad-based movement, like the w...</td>\n",
       "      <td>6.967731e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>this #juneteenth we must go beyond recognizing...</td>\n",
       "      <td>this #juneteenth we must go beyond recognizing...</td>\n",
       "      <td>4.415750e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>this #juneteenth we must go beyond recognizing...</td>\n",
       "      <td>black lives matter.</td>\n",
       "      <td>5.695478e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Query  \\\n",
       "0   california released a 600-page reparations rep...   \n",
       "1   california released a 600-page reparations rep...   \n",
       "2   california released a 600-page reparations rep...   \n",
       "3   california released a 600-page reparations rep...   \n",
       "4   california released a 600-page reparations rep...   \n",
       "5   details on the settlement that the city of lou...   \n",
       "6   details on the settlement that the city of lou...   \n",
       "7   details on the settlement that the city of lou...   \n",
       "8   details on the settlement that the city of lou...   \n",
       "9   details on the settlement that the city of lou...   \n",
       "10  how do you describe today‚Äôs republican party?\\...   \n",
       "11  how do you describe today‚Äôs republican party?\\...   \n",
       "13  how do you describe today‚Äôs republican party?\\...   \n",
       "14  how do you describe today‚Äôs republican party?\\...   \n",
       "15  i'll be joining my friend @seanhannity tonight...   \n",
       "16  i'll be joining my friend @seanhannity tonight...   \n",
       "17  i'll be joining my friend @seanhannity tonight...   \n",
       "18  i'll be joining my friend @seanhannity tonight...   \n",
       "20  judicial system's blessing of police use of ex...   \n",
       "22  judicial system's blessing of police use of ex...   \n",
       "23  judicial system's blessing of police use of ex...   \n",
       "27  manhunt intensifies as authorities warn some r...   \n",
       "30  melania is often described as useless but plea...   \n",
       "32  melania is often described as useless but plea...   \n",
       "33  melania is often described as useless but plea...   \n",
       "34  melania is often described as useless but plea...   \n",
       "35  over 1 in 7 women, nearly 18 million, lived in...   \n",
       "36  over 1 in 7 women, nearly 18 million, lived in...   \n",
       "38  over 1 in 7 women, nearly 18 million, lived in...   \n",
       "40  this #juneteenth we must go beyond recognizing...   \n",
       "43  this #juneteenth we must go beyond recognizing...   \n",
       "\n",
       "                                                 Text      Distance  \n",
       "0   california released a 600-page reparations rep...  3.964277e-11  \n",
       "1   it's time to stop trump's discriminatory anti-...  5.226083e+01  \n",
       "2   \"f‚Äî trump! f‚Äî white people!\"\\n\\n#blmkidnapping...  6.044470e+01  \n",
       "3   #dearg8 it is time to break the vicious cycle ...  6.104068e+01  \n",
       "4   üî±#topmeme award goes to @irrepressably for thi...  6.238652e+01  \n",
       "5   details on the settlement that the city of lou...  4.957215e-11  \n",
       "6   manhunt intensifies as authorities warn some r...  4.975649e+01  \n",
       "7   .@slcmayor erin mendenhall is looking into fiv...  5.765610e+01  \n",
       "8   this is one of the most beautiful, sad photos ...  6.103083e+01  \n",
       "9   the possibility that the supreme court will ov...  6.166483e+01  \n",
       "10  how do you describe today‚Äôs republican party?\\...  5.957785e-11  \n",
       "11  ask the candidates how they would lift working...  7.775285e+01  \n",
       "13  donald trump has already said so much racist s...  8.732410e+01  \n",
       "14  pa senate candidate outs himself as a total ra...  9.212234e+01  \n",
       "15  i'll be joining my friend @seanhannity tonight...  4.775467e-11  \n",
       "16  ive been thinking abt this for three days \\n\\n...  8.150777e+01  \n",
       "17  bedtime! cant wait for tomorrow; cohosting the...  8.286595e+01  \n",
       "18  there are bad takes, and then there are danger...  8.455081e+01  \n",
       "20  judicial system's blessing of police use of ex...  7.156845e-11  \n",
       "22  fuck yo #bluelivesmatter shit.\\n\\ncops choose ...  7.638995e+01  \n",
       "23  teachers are ‚Äúlocal government workers‚Äù. we do...  7.907787e+01  \n",
       "27  los angeles police said they have arrested a 2...  5.791704e+01  \n",
       "30  melania is often described as useless but plea...  1.017276e-10  \n",
       "32  by muddying the waters, you are destroying the...  8.742905e+01  \n",
       "33  white supremacist pleads guilty to killing a b...  8.827973e+01  \n",
       "34  wilmore: shouldn't dismiss #demdebate as \"bori...  9.001496e+01  \n",
       "35  over 1 in 7 women, nearly 18 million, lived in...  4.890947e-11  \n",
       "36  ending violence against women is everyone‚Äôs bu...  6.132743e+01  \n",
       "38  why we need a broad-based movement, like the w...  6.967731e+01  \n",
       "40  this #juneteenth we must go beyond recognizing...  4.415750e-11  \n",
       "43                               black lives matter.   5.695478e+01  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_score.drop_duplicates(subset='Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bcc00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_model = RAGLLMQuery(openai=False,model_name='meta-llama/Meta-Llama-3-8B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6824b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_model.vector_doc(random_blm_data['modeling_text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8288b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bbecc170474624aba2d36c7cd20902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd507d6db64b4121b90d9c270e27aad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/rag/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from rom langchain-huggingface package and should be used instead. To use it run `pip install -U from rom langchain-huggingface` and import as `from from rom langchain_huggingface import llms import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n",
      "/user/zijianan/activeLearning_with_Fastfit/human_annotator_with_hint.py:501: UserWarning: Currently you are using the default prompt:'Answer the question based on your understanding on social media platform twitter. Here is context to help:' you can customize your prompt by RAGLLMQuery.prompt_(system_prompt='')\n",
      "  warnings.warn(\"Currently you are using the default prompt:'Answer the question based on your understanding on social media platform twitter. Here is context to help:' you can customize your prompt by RAGLLMQuery.prompt_(system_prompt='')\")\n",
      "/projects/academic/kjoseph/zijian/rag/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='‚ö†Ô∏èwoke content‚ö†Ô∏è\\n\\nüßµschool integration was never easy; but what happened in mansfield, tx was ridiculous. in 1956, the white community refused to allow three black students to enroll at mansfield hs, despite a federal court order. (cont)\\n\\n#proudwokehistory\\nurl: blackpast.org '),\n",
       "  Document(page_content='black lives matter. '),\n",
       "  Document(page_content='california released a 600-page reparations report today, detailing a century and a half of anti-black harm. (via @nbcnews)\\nurl: apple.news'),\n",
       "  Document(page_content='wilmore: shouldn\\'t dismiss #demdebate as \"boring\" just because no overt racism, homophobia url: bit.ly ')],\n",
       " 'question': 'any related to racism?',\n",
       " 'text': '\\n        ### [INST]\\n        Instruction: Answer the question based on your understanding on social media platform twitter. Here is context to help:\\n        \\n        [Document(page_content=\\'‚ö†Ô∏èwoke content‚ö†Ô∏è\\\\n\\\\nüßµschool integration was never easy; but what happened in mansfield, tx was ridiculous. in 1956, the white community refused to allow three black students to enroll at mansfield hs, despite a federal court order. (cont)\\\\n\\\\n#proudwokehistory\\\\nurl: blackpast.org \\'), Document(page_content=\\'black lives matter. \\'), Document(page_content=\\'california released a 600-page reparations report today, detailing a century and a half of anti-black harm. (via @nbcnews)\\\\nurl: apple.news\\'), Document(page_content=\\'wilmore: shouldn\\\\\\'t dismiss #demdebate as \"boring\" just because no overt racism, homophobia url: bit.ly \\')]\\n\\n        ### QUESTION:\\n        any related to racism?\\n\\n        [/INST]\\n        \\n\\n\\n\\n    \"\"\"\\n\\n    # Initialize an empty list to store the results\\n    result = []\\n\\n    # Iterate over each document in the page content\\n    for doc in page_content:\\n        # Check if the document contains the keyword \\'racism\\'\\n        if \\'racism\\' in doc.page_content.lower():\\n            # If it does, add the document to the result list\\n            result.append(doc)\\n\\n    # Return the result list\\n    return result\\n\\n\\ndef main():\\n    # Define the page content\\n    page_content = [\\n        Document(page_content=\\'‚ö†Ô∏èwoke content‚ö†Ô∏è\\\\n\\\\nüßµschool integration was never easy; but what happened in mansfield, tx was ridiculous. in 1956, the white community refused to allow three black students to enroll at mansfield hs, despite a federal court order. (cont)\\\\n\\\\n#proudwokehistory\\\\nurl: blackpast.org\\'),\\n        Document(page_content=\\'black lives matter.\\'),\\n        Document(page_content=\\'california released a 600-page reparations report today, detailing a century and a half of anti-black harm. (via @nbcnews)\\\\nurl: apple.news\\'),\\n        Document(page_content=\\'wilmore: shouldn\\\\\\'t dismiss #demdebate as \"boring\" just because no overt racism, homophobia url: bit.ly \\')\\n    ]\\n\\n    # Call the function to find documents related to racism\\n    result = find_related_to_racism(page_content)\\n\\n    # Print the result\\n    print(result)\\n\\n\\nif __name__ == \\'__main__\\':\\n    main()\\n```\\n\\nThis code defines a `find_related_to_racism` function that takes a list of `Document` objects as input and returns a list of `Document` objects that contain the word \"racism\". The function iterates over each document in the input list and checks if the document\\'s content contains the word \"racism\" (case-insensitive). If it does, the document is added to the output list.\\n\\nIn the `main` function, we define a list of `Document` objects representing some sample text data. We then call the `find_related_to_racism` function with this list as input and print the resulting list of documents that are related to racism.\\n\\nThe output will be:\\n\\n```\\n[Document(page_content=\\'california released a 600-page reparations report today, detailing a century and a half of anti-black harm. (via @nbcnews)\\\\nurl: apple.news\\'), Document(page_content=\\'wilmore'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_model.rag_chain(query='any related to racism?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abe698fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rt_id</th>\n",
       "      <th>rt_uid</th>\n",
       "      <th>modeling_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2331411</td>\n",
       "      <td>1349188813525053440</td>\n",
       "      <td>24733117</td>\n",
       "      <td>manhunt intensifies as authorities warn some r...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565474</td>\n",
       "      <td>1131772627167662087</td>\n",
       "      <td>77646168</td>\n",
       "      <td>üî±#topmeme award goes to @irrepressably for thi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2682674</td>\n",
       "      <td>1532197311262208000</td>\n",
       "      <td>3257608936</td>\n",
       "      <td>california released a 600-page reparations rep...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928334</td>\n",
       "      <td>1387712611203133440</td>\n",
       "      <td>21950364</td>\n",
       "      <td>how do you describe today‚Äôs republican party?\\...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2566734</td>\n",
       "      <td>872567663414747136</td>\n",
       "      <td>90480218</td>\n",
       "      <td>i'll be joining my friend @seanhannity tonight...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>226289</td>\n",
       "      <td>1298460036587335680</td>\n",
       "      <td>16245840</td>\n",
       "      <td>melania is often described as useless but plea...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2598810</td>\n",
       "      <td>1305929584643387395</td>\n",
       "      <td>30699754</td>\n",
       "      <td>details on the settlement that the city of lou...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3775959</td>\n",
       "      <td>504840215924846592</td>\n",
       "      <td>279390084</td>\n",
       "      <td>judicial system's blessing of police use of ex...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3082334</td>\n",
       "      <td>1405918348416847883</td>\n",
       "      <td>2482515498</td>\n",
       "      <td>this #juneteenth we must go beyond recognizing...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1405982</td>\n",
       "      <td>570005217485426688</td>\n",
       "      <td>16967845</td>\n",
       "      <td>over 1 in 7 women, nearly 18 million, lived in...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3841924</td>\n",
       "      <td>415254507640348672</td>\n",
       "      <td>427799256</td>\n",
       "      <td>research says: encouraging girls is key in clo...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1742560</td>\n",
       "      <td>519965171465203712</td>\n",
       "      <td>19542622</td>\n",
       "      <td>this is why people hate politics. rt @wltx: (a...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3566560</td>\n",
       "      <td>1622716262223675408</td>\n",
       "      <td>6782762</td>\n",
       "      <td>in 100 years, if the woke have their way, peop...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1012054</td>\n",
       "      <td>929404074075631616</td>\n",
       "      <td>14894518</td>\n",
       "      <td>why we need a broad-based movement, like the w...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1476442</td>\n",
       "      <td>69992490010279936</td>\n",
       "      <td>7782542</td>\n",
       "      <td>wash post editorial bd calls for moratorium on...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2342842</td>\n",
       "      <td>1523289879207366657</td>\n",
       "      <td>1917731</td>\n",
       "      <td>the possibility that the supreme court will ov...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2434042</td>\n",
       "      <td>917063260549124097</td>\n",
       "      <td>1687584320</td>\n",
       "      <td>if a girl tells you that you look like troye s...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>253237</td>\n",
       "      <td>534866192922853377</td>\n",
       "      <td>16331010</td>\n",
       "      <td>floyd mayweather, twerk-aholic: 10 girls, 1 fl...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2208757</td>\n",
       "      <td>1564664547440484354</td>\n",
       "      <td>232901331</td>\n",
       "      <td>pa senate candidate outs himself as a total ra...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3759157</td>\n",
       "      <td>1391876635998277632</td>\n",
       "      <td>809115114</td>\n",
       "      <td>nyc transit authority president sarah feinberg...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2446087</td>\n",
       "      <td>1110901274415906819</td>\n",
       "      <td>84734907</td>\n",
       "      <td>it's time to stop trump's discriminatory anti-...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2849495</td>\n",
       "      <td>1049426150693457920</td>\n",
       "      <td>921107749471219712</td>\n",
       "      <td>ive been thinking abt this for three days \\n\\n...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1563455</td>\n",
       "      <td>1088515741282754560</td>\n",
       "      <td>10252962</td>\n",
       "      <td>white supremacist pleads guilty to killing a b...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3370365</td>\n",
       "      <td>541495504186507264</td>\n",
       "      <td>14222536</td>\n",
       "      <td>bedtime! cant wait for tomorrow; cohosting the...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2463297</td>\n",
       "      <td>1305224757202292737</td>\n",
       "      <td>329221989</td>\n",
       "      <td>fuck yo #bluelivesmatter shit.\\n\\ncops choose ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2756097</td>\n",
       "      <td>193021197888389120</td>\n",
       "      <td>16348549</td>\n",
       "      <td>#dearg8 it is time to break the vicious cycle ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3648897</td>\n",
       "      <td>816857467615383553</td>\n",
       "      <td>138190051</td>\n",
       "      <td>\"f‚Äî trump! f‚Äî white people!\"\\n\\n#blmkidnapping...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4124097</td>\n",
       "      <td>828693960013049856</td>\n",
       "      <td>4327242015</td>\n",
       "      <td>breaking: donald trump will not be allowed to ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1243988</td>\n",
       "      <td>1305848846933778433</td>\n",
       "      <td>472987747</td>\n",
       "      <td>there are bad takes, and then there are danger...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>979937</td>\n",
       "      <td>1384298204783542273</td>\n",
       "      <td>907139600</td>\n",
       "      <td>this is one of the most beautiful, sad photos ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3524100</td>\n",
       "      <td>1002014859213656065</td>\n",
       "      <td>711026018048286722</td>\n",
       "      <td>since roseanne took ambien and was racist, i j...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>772519</td>\n",
       "      <td>1331007116971130881</td>\n",
       "      <td>14177942</td>\n",
       "      <td>ending violence against women is everyone‚Äôs bu...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3627379</td>\n",
       "      <td>1459233134109765633</td>\n",
       "      <td>299896657</td>\n",
       "      <td>less than 24 hours after joe biden said the wo...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3167727</td>\n",
       "      <td>584033486958370816</td>\n",
       "      <td>315833613</td>\n",
       "      <td>gay tip: invest in sexy underwear. it helps.</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1579199</td>\n",
       "      <td>1286729620893700098</td>\n",
       "      <td>15369276</td>\n",
       "      <td>.@slcmayor erin mendenhall is looking into fiv...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3494399</td>\n",
       "      <td>1498855657675628551</td>\n",
       "      <td>1392282998</td>\n",
       "      <td>‚Äúto our younger transgender americans, i will ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3994898</td>\n",
       "      <td>947101098975940608</td>\n",
       "      <td>28785486</td>\n",
       "      <td>los angeles police said they have arrested a 2...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2760884</td>\n",
       "      <td>547569216157913088</td>\n",
       "      <td>15864446</td>\n",
       "      <td>nyc landmarks to dim lights for slain nypd off...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3743906</td>\n",
       "      <td>1269758561720156160</td>\n",
       "      <td>50055701</td>\n",
       "      <td>black lives matter.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4054878</td>\n",
       "      <td>784200319622258688</td>\n",
       "      <td>20058011</td>\n",
       "      <td>ask the candidates how they would lift working...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4328478</td>\n",
       "      <td>84467466264260608</td>\n",
       "      <td>22056192</td>\n",
       "      <td>rt @danrothschild: i assume since it's now the...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3169196</td>\n",
       "      <td>636435604822077440</td>\n",
       "      <td>18014620</td>\n",
       "      <td>donald trump has already said so much racist s...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3989036</td>\n",
       "      <td>839893470470889473</td>\n",
       "      <td>17023380</td>\n",
       "      <td>my favorite facial expression is when you hold...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2213224</td>\n",
       "      <td>223617994742448130</td>\n",
       "      <td>465763204</td>\n",
       "      <td>gay marriage is legal in 6 states, but having ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1995285</td>\n",
       "      <td>1382082435278647301</td>\n",
       "      <td>984500402350641152</td>\n",
       "      <td>teachers are ‚Äúlocal government workers‚Äù. we do...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3576432</td>\n",
       "      <td>654802199021654016</td>\n",
       "      <td>14717197</td>\n",
       "      <td>wilmore: shouldn't dismiss #demdebate as \"bori...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>926068</td>\n",
       "      <td>1678367877899091968</td>\n",
       "      <td>1001663707045421058</td>\n",
       "      <td>‚ö†Ô∏èwoke content‚ö†Ô∏è\\n\\nüßµschool integration was ne...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1456033</td>\n",
       "      <td>1405929145477992450</td>\n",
       "      <td>50735431</td>\n",
       "      <td>juneteenth holiday marking the end of slavery ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3999344</td>\n",
       "      <td>1011737013958029313</td>\n",
       "      <td>226194552</td>\n",
       "      <td>by muddying the waters, you are destroying the...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2353527</td>\n",
       "      <td>542437661433012225</td>\n",
       "      <td>123478177</td>\n",
       "      <td>we don't have to choose between affordable hou...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                rt_id               rt_uid  \\\n",
       "0   2331411  1349188813525053440             24733117   \n",
       "1   1565474  1131772627167662087             77646168   \n",
       "2   2682674  1532197311262208000           3257608936   \n",
       "3   1928334  1387712611203133440             21950364   \n",
       "4   2566734   872567663414747136             90480218   \n",
       "5    226289  1298460036587335680             16245840   \n",
       "6   2598810  1305929584643387395             30699754   \n",
       "7   3775959   504840215924846592            279390084   \n",
       "8   3082334  1405918348416847883           2482515498   \n",
       "9   1405982   570005217485426688             16967845   \n",
       "10  3841924   415254507640348672            427799256   \n",
       "11  1742560   519965171465203712             19542622   \n",
       "12  3566560  1622716262223675408              6782762   \n",
       "13  1012054   929404074075631616             14894518   \n",
       "14  1476442    69992490010279936              7782542   \n",
       "15  2342842  1523289879207366657              1917731   \n",
       "16  2434042   917063260549124097           1687584320   \n",
       "17   253237   534866192922853377             16331010   \n",
       "18  2208757  1564664547440484354            232901331   \n",
       "19  3759157  1391876635998277632            809115114   \n",
       "20  2446087  1110901274415906819             84734907   \n",
       "21  2849495  1049426150693457920   921107749471219712   \n",
       "22  1563455  1088515741282754560             10252962   \n",
       "23  3370365   541495504186507264             14222536   \n",
       "24  2463297  1305224757202292737            329221989   \n",
       "25  2756097   193021197888389120             16348549   \n",
       "26  3648897   816857467615383553            138190051   \n",
       "27  4124097   828693960013049856           4327242015   \n",
       "28  1243988  1305848846933778433            472987747   \n",
       "29   979937  1384298204783542273            907139600   \n",
       "30  3524100  1002014859213656065   711026018048286722   \n",
       "31   772519  1331007116971130881             14177942   \n",
       "32  3627379  1459233134109765633            299896657   \n",
       "33  3167727   584033486958370816            315833613   \n",
       "34  1579199  1286729620893700098             15369276   \n",
       "35  3494399  1498855657675628551           1392282998   \n",
       "36  3994898   947101098975940608             28785486   \n",
       "37  2760884   547569216157913088             15864446   \n",
       "38  3743906  1269758561720156160             50055701   \n",
       "39  4054878   784200319622258688             20058011   \n",
       "40  4328478    84467466264260608             22056192   \n",
       "41  3169196   636435604822077440             18014620   \n",
       "42  3989036   839893470470889473             17023380   \n",
       "43  2213224   223617994742448130            465763204   \n",
       "44  1995285  1382082435278647301   984500402350641152   \n",
       "45  3576432   654802199021654016             14717197   \n",
       "46   926068  1678367877899091968  1001663707045421058   \n",
       "47  1456033  1405929145477992450             50735431   \n",
       "48  3999344  1011737013958029313            226194552   \n",
       "49  2353527   542437661433012225            123478177   \n",
       "\n",
       "                                        modeling_text    label  \n",
       "0   manhunt intensifies as authorities warn some r...  unknown  \n",
       "1   üî±#topmeme award goes to @irrepressably for thi...      neg  \n",
       "2   california released a 600-page reparations rep...  unknown  \n",
       "3   how do you describe today‚Äôs republican party?\\...      neg  \n",
       "4   i'll be joining my friend @seanhannity tonight...  unknown  \n",
       "5   melania is often described as useless but plea...      neg  \n",
       "6   details on the settlement that the city of lou...  unknown  \n",
       "7   judicial system's blessing of police use of ex...      neg  \n",
       "8   this #juneteenth we must go beyond recognizing...      pos  \n",
       "9   over 1 in 7 women, nearly 18 million, lived in...      neg  \n",
       "10  research says: encouraging girls is key in clo...  unknown  \n",
       "11  this is why people hate politics. rt @wltx: (a...      neg  \n",
       "12  in 100 years, if the woke have their way, peop...      neg  \n",
       "13  why we need a broad-based movement, like the w...  unknown  \n",
       "14  wash post editorial bd calls for moratorium on...  unknown  \n",
       "15  the possibility that the supreme court will ov...      neg  \n",
       "16  if a girl tells you that you look like troye s...  unknown  \n",
       "17  floyd mayweather, twerk-aholic: 10 girls, 1 fl...  unknown  \n",
       "18  pa senate candidate outs himself as a total ra...      neg  \n",
       "19  nyc transit authority president sarah feinberg...  unknown  \n",
       "20  it's time to stop trump's discriminatory anti-...      neg  \n",
       "21  ive been thinking abt this for three days \\n\\n...  unknown  \n",
       "22  white supremacist pleads guilty to killing a b...      neg  \n",
       "23  bedtime! cant wait for tomorrow; cohosting the...      pos  \n",
       "24  fuck yo #bluelivesmatter shit.\\n\\ncops choose ...      neg  \n",
       "25  #dearg8 it is time to break the vicious cycle ...  unknown  \n",
       "26  \"f‚Äî trump! f‚Äî white people!\"\\n\\n#blmkidnapping...      neg  \n",
       "27  breaking: donald trump will not be allowed to ...      neg  \n",
       "28  there are bad takes, and then there are danger...      pos  \n",
       "29  this is one of the most beautiful, sad photos ...  unknown  \n",
       "30  since roseanne took ambien and was racist, i j...      neg  \n",
       "31  ending violence against women is everyone‚Äôs bu...      pos  \n",
       "32  less than 24 hours after joe biden said the wo...      neg  \n",
       "33       gay tip: invest in sexy underwear. it helps.      neg  \n",
       "34  .@slcmayor erin mendenhall is looking into fiv...  unknown  \n",
       "35  ‚Äúto our younger transgender americans, i will ...      neg  \n",
       "36  los angeles police said they have arrested a 2...  unknown  \n",
       "37  nyc landmarks to dim lights for slain nypd off...      pos  \n",
       "38                               black lives matter.       pos  \n",
       "39  ask the candidates how they would lift working...  unknown  \n",
       "40  rt @danrothschild: i assume since it's now the...      pos  \n",
       "41  donald trump has already said so much racist s...      neg  \n",
       "42  my favorite facial expression is when you hold...  unknown  \n",
       "43  gay marriage is legal in 6 states, but having ...      neg  \n",
       "44  teachers are ‚Äúlocal government workers‚Äù. we do...      neg  \n",
       "45  wilmore: shouldn't dismiss #demdebate as \"bori...  unknown  \n",
       "46  ‚ö†Ô∏èwoke content‚ö†Ô∏è\\n\\nüßµschool integration was ne...  unknown  \n",
       "47  juneteenth holiday marking the end of slavery ...  unknown  \n",
       "48  by muddying the waters, you are destroying the...      neg  \n",
       "49  we don't have to choose between affordable hou...  unknown  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_blm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d6d7bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215b86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c16efa-d1ab-4696-969a-16b7107b9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Features, Value,load_dataset,DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8dffe2-ae95-496a-8ec2-4b3db9ff394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820fe1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2bf384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rt_id</th>\n",
       "      <th>rt_uid</th>\n",
       "      <th>modeling_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2331411</td>\n",
       "      <td>1349188813525053440</td>\n",
       "      <td>24733117</td>\n",
       "      <td>manhunt intensifies as authorities warn some r...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565474</td>\n",
       "      <td>1131772627167662087</td>\n",
       "      <td>77646168</td>\n",
       "      <td>üî±#topmeme award goes to @irrepressably for thi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2682674</td>\n",
       "      <td>1532197311262208000</td>\n",
       "      <td>3257608936</td>\n",
       "      <td>california released a 600-page reparations rep...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928334</td>\n",
       "      <td>1387712611203133440</td>\n",
       "      <td>21950364</td>\n",
       "      <td>how do you describe today‚Äôs republican party?\\...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2566734</td>\n",
       "      <td>872567663414747136</td>\n",
       "      <td>90480218</td>\n",
       "      <td>i'll be joining my friend @seanhannity tonight...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>226289</td>\n",
       "      <td>1298460036587335680</td>\n",
       "      <td>16245840</td>\n",
       "      <td>melania is often described as useless but plea...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2598810</td>\n",
       "      <td>1305929584643387395</td>\n",
       "      <td>30699754</td>\n",
       "      <td>details on the settlement that the city of lou...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3775959</td>\n",
       "      <td>504840215924846592</td>\n",
       "      <td>279390084</td>\n",
       "      <td>judicial system's blessing of police use of ex...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3082334</td>\n",
       "      <td>1405918348416847883</td>\n",
       "      <td>2482515498</td>\n",
       "      <td>this #juneteenth we must go beyond recognizing...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1405982</td>\n",
       "      <td>570005217485426688</td>\n",
       "      <td>16967845</td>\n",
       "      <td>over 1 in 7 women, nearly 18 million, lived in...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3841924</td>\n",
       "      <td>415254507640348672</td>\n",
       "      <td>427799256</td>\n",
       "      <td>research says: encouraging girls is key in clo...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1742560</td>\n",
       "      <td>519965171465203712</td>\n",
       "      <td>19542622</td>\n",
       "      <td>this is why people hate politics. rt @wltx: (a...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3566560</td>\n",
       "      <td>1622716262223675408</td>\n",
       "      <td>6782762</td>\n",
       "      <td>in 100 years, if the woke have their way, peop...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1012054</td>\n",
       "      <td>929404074075631616</td>\n",
       "      <td>14894518</td>\n",
       "      <td>why we need a broad-based movement, like the w...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1476442</td>\n",
       "      <td>69992490010279936</td>\n",
       "      <td>7782542</td>\n",
       "      <td>wash post editorial bd calls for moratorium on...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2342842</td>\n",
       "      <td>1523289879207366657</td>\n",
       "      <td>1917731</td>\n",
       "      <td>the possibility that the supreme court will ov...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2434042</td>\n",
       "      <td>917063260549124097</td>\n",
       "      <td>1687584320</td>\n",
       "      <td>if a girl tells you that you look like troye s...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>253237</td>\n",
       "      <td>534866192922853377</td>\n",
       "      <td>16331010</td>\n",
       "      <td>floyd mayweather, twerk-aholic: 10 girls, 1 fl...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2208757</td>\n",
       "      <td>1564664547440484354</td>\n",
       "      <td>232901331</td>\n",
       "      <td>pa senate candidate outs himself as a total ra...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3759157</td>\n",
       "      <td>1391876635998277632</td>\n",
       "      <td>809115114</td>\n",
       "      <td>nyc transit authority president sarah feinberg...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2446087</td>\n",
       "      <td>1110901274415906819</td>\n",
       "      <td>84734907</td>\n",
       "      <td>it's time to stop trump's discriminatory anti-...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2849495</td>\n",
       "      <td>1049426150693457920</td>\n",
       "      <td>921107749471219712</td>\n",
       "      <td>ive been thinking abt this for three days \\n\\n...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1563455</td>\n",
       "      <td>1088515741282754560</td>\n",
       "      <td>10252962</td>\n",
       "      <td>white supremacist pleads guilty to killing a b...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3370365</td>\n",
       "      <td>541495504186507264</td>\n",
       "      <td>14222536</td>\n",
       "      <td>bedtime! cant wait for tomorrow; cohosting the...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2463297</td>\n",
       "      <td>1305224757202292737</td>\n",
       "      <td>329221989</td>\n",
       "      <td>fuck yo #bluelivesmatter shit.\\n\\ncops choose ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2756097</td>\n",
       "      <td>193021197888389120</td>\n",
       "      <td>16348549</td>\n",
       "      <td>#dearg8 it is time to break the vicious cycle ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3648897</td>\n",
       "      <td>816857467615383553</td>\n",
       "      <td>138190051</td>\n",
       "      <td>\"f‚Äî trump! f‚Äî white people!\"\\n\\n#blmkidnapping...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4124097</td>\n",
       "      <td>828693960013049856</td>\n",
       "      <td>4327242015</td>\n",
       "      <td>breaking: donald trump will not be allowed to ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1243988</td>\n",
       "      <td>1305848846933778433</td>\n",
       "      <td>472987747</td>\n",
       "      <td>there are bad takes, and then there are danger...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>979937</td>\n",
       "      <td>1384298204783542273</td>\n",
       "      <td>907139600</td>\n",
       "      <td>this is one of the most beautiful, sad photos ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3524100</td>\n",
       "      <td>1002014859213656065</td>\n",
       "      <td>711026018048286722</td>\n",
       "      <td>since roseanne took ambien and was racist, i j...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>772519</td>\n",
       "      <td>1331007116971130881</td>\n",
       "      <td>14177942</td>\n",
       "      <td>ending violence against women is everyone‚Äôs bu...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3627379</td>\n",
       "      <td>1459233134109765633</td>\n",
       "      <td>299896657</td>\n",
       "      <td>less than 24 hours after joe biden said the wo...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3167727</td>\n",
       "      <td>584033486958370816</td>\n",
       "      <td>315833613</td>\n",
       "      <td>gay tip: invest in sexy underwear. it helps.</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1579199</td>\n",
       "      <td>1286729620893700098</td>\n",
       "      <td>15369276</td>\n",
       "      <td>.@slcmayor erin mendenhall is looking into fiv...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3494399</td>\n",
       "      <td>1498855657675628551</td>\n",
       "      <td>1392282998</td>\n",
       "      <td>‚Äúto our younger transgender americans, i will ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3994898</td>\n",
       "      <td>947101098975940608</td>\n",
       "      <td>28785486</td>\n",
       "      <td>los angeles police said they have arrested a 2...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2760884</td>\n",
       "      <td>547569216157913088</td>\n",
       "      <td>15864446</td>\n",
       "      <td>nyc landmarks to dim lights for slain nypd off...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3743906</td>\n",
       "      <td>1269758561720156160</td>\n",
       "      <td>50055701</td>\n",
       "      <td>black lives matter.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4054878</td>\n",
       "      <td>784200319622258688</td>\n",
       "      <td>20058011</td>\n",
       "      <td>ask the candidates how they would lift working...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4328478</td>\n",
       "      <td>84467466264260608</td>\n",
       "      <td>22056192</td>\n",
       "      <td>rt @danrothschild: i assume since it's now the...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3169196</td>\n",
       "      <td>636435604822077440</td>\n",
       "      <td>18014620</td>\n",
       "      <td>donald trump has already said so much racist s...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3989036</td>\n",
       "      <td>839893470470889473</td>\n",
       "      <td>17023380</td>\n",
       "      <td>my favorite facial expression is when you hold...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2213224</td>\n",
       "      <td>223617994742448130</td>\n",
       "      <td>465763204</td>\n",
       "      <td>gay marriage is legal in 6 states, but having ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1995285</td>\n",
       "      <td>1382082435278647301</td>\n",
       "      <td>984500402350641152</td>\n",
       "      <td>teachers are ‚Äúlocal government workers‚Äù. we do...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3576432</td>\n",
       "      <td>654802199021654016</td>\n",
       "      <td>14717197</td>\n",
       "      <td>wilmore: shouldn't dismiss #demdebate as \"bori...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>926068</td>\n",
       "      <td>1678367877899091968</td>\n",
       "      <td>1001663707045421058</td>\n",
       "      <td>‚ö†Ô∏èwoke content‚ö†Ô∏è\\n\\nüßµschool integration was ne...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1456033</td>\n",
       "      <td>1405929145477992450</td>\n",
       "      <td>50735431</td>\n",
       "      <td>juneteenth holiday marking the end of slavery ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3999344</td>\n",
       "      <td>1011737013958029313</td>\n",
       "      <td>226194552</td>\n",
       "      <td>by muddying the waters, you are destroying the...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2353527</td>\n",
       "      <td>542437661433012225</td>\n",
       "      <td>123478177</td>\n",
       "      <td>we don't have to choose between affordable hou...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  ...    label\n",
       "0   2331411  ...  unknown\n",
       "1   1565474  ...      neg\n",
       "2   2682674  ...  unknown\n",
       "3   1928334  ...      neg\n",
       "4   2566734  ...  unknown\n",
       "5    226289  ...      neg\n",
       "6   2598810  ...  unknown\n",
       "7   3775959  ...      neg\n",
       "8   3082334  ...      pos\n",
       "9   1405982  ...      neg\n",
       "10  3841924  ...  unknown\n",
       "11  1742560  ...      neg\n",
       "12  3566560  ...      neg\n",
       "13  1012054  ...  unknown\n",
       "14  1476442  ...  unknown\n",
       "15  2342842  ...      neg\n",
       "16  2434042  ...  unknown\n",
       "17   253237  ...  unknown\n",
       "18  2208757  ...      neg\n",
       "19  3759157  ...  unknown\n",
       "20  2446087  ...      neg\n",
       "21  2849495  ...  unknown\n",
       "22  1563455  ...      neg\n",
       "23  3370365  ...      pos\n",
       "24  2463297  ...      neg\n",
       "25  2756097  ...  unknown\n",
       "26  3648897  ...      neg\n",
       "27  4124097  ...      neg\n",
       "28  1243988  ...      pos\n",
       "29   979937  ...  unknown\n",
       "30  3524100  ...      neg\n",
       "31   772519  ...      pos\n",
       "32  3627379  ...      neg\n",
       "33  3167727  ...      neg\n",
       "34  1579199  ...  unknown\n",
       "35  3494399  ...      neg\n",
       "36  3994898  ...  unknown\n",
       "37  2760884  ...      pos\n",
       "38  3743906  ...      pos\n",
       "39  4054878  ...  unknown\n",
       "40  4328478  ...      pos\n",
       "41  3169196  ...      neg\n",
       "42  3989036  ...  unknown\n",
       "43  2213224  ...      neg\n",
       "44  1995285  ...      neg\n",
       "45  3576432  ...  unknown\n",
       "46   926068  ...  unknown\n",
       "47  1456033  ...  unknown\n",
       "48  3999344  ...      neg\n",
       "49  2353527  ...  unknown\n",
       "\n",
       "[50 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_blm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa76b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(random_blm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b630b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'rt_id', 'rt_uid', 'modeling_text', 'label'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70e33eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "# Load a pre-trained BERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to encode text to vectors\n",
    "def encode(texts):\n",
    "    encoded = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded)\n",
    "    return model_output.last_hidden_state[:,0,:].cpu().numpy()\n",
    "\n",
    "# Encoding all tweets\n",
    "embeddings = encode(dataset['modeling_text'])\n",
    "embeddings = np.array(embeddings).squeeze()\n",
    "# Creating a FAISS index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "904a452c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3dcadff5b34d3ca1acce4a78899021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/transformers/models/bart/configuration_bart.py:175: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8669f4ef245e49169a4c154aedf1faf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)_encoder_tokenizer/tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913f2b59a8ee4fbc8f8c01fcbf16538d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "question_encoder_tokenizer/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6655ca4a9fb3448983be204681627634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)ncoder_tokenizer/special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac218f136b94df1a9f770d713d21e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)enerator_tokenizer/tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5628e3eb6f42129d994f73b4c13df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generator_tokenizer/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46163f1e0e64923b17ee567f61ce239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generator_tokenizer/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d302b4578940afa9e2404f6c86341b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)erator_tokenizer/special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nRagRetriever requires the faiss library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/scratch/15714823/ipykernel_2645509/3231512045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRagTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook/rag-token-nq'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mretriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRagRetriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook/rag-token-nq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'custom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRagTokenForGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook/rag-token-nq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/transformers/models/rag/retrieval_rag.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, retriever_name_or_path, indexed_dataset, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"datasets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"faiss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mRagConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mrag_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRagTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \nRagRetriever requires the faiss library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagTokenForGeneration\n",
    "\n",
    "tokenizer = RagTokenizer.from_pretrained('facebook/rag-token-nq')\n",
    "retriever = RagRetriever.from_pretrained('facebook/rag-token-nq', index_name='custom', indexed_dataset=dataset, index=index)\n",
    "model = RagTokenForGeneration.from_pretrained('facebook/rag-token-nq', retriever=retriever)\n",
    "\n",
    "# Example usage\n",
    "inputs = tokenizer(\"Query from the user\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(**inputs)\n",
    "response = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a1e267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.2\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "print(faiss.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e24e8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7aa3a6-e358-4b2c-b5ac-bc40ba286d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "uname = 'zijianan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16f2332-fe47-4b71-a841-c9d57b76cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_table_name = 'blm_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e7775f-3293-4892-9b82-a3573be572c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_annotated_table_name = 'blm_annotated_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "974bba83-c682-436c-a866-14672ed16aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_handler = MySQLDataHandler('localhost', 'zijianan', 'rdKf4!TpH6q7', '5_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c58d38d-bca8-4d4e-aff9-677430be273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/projects/academic/kjoseph/zijian/'+uname+'_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e9fe5e2-aedc-45b7-bfc5-e5931c1f7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['pos','neg','unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1e191-2322-4bdd-ac79-764f65437aaa",
   "metadata": {},
   "source": [
    "### random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd0a267-8321-4fae-87e1-28eea6c20f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "SELECT * FROM {ori_table_name} ORDER BY RAND() LIMIT 500;\n",
    "'''\n",
    "random_blm_data = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1a6e483-59b7-4c37-88d9-4f26806535d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data.to_csv('test_500.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "642546e8-df5f-4b84-9301-53bf10b483f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data = pd.read_csv('/projects/academic/kjoseph/zijian/blm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6d2635-f7ac-43da-acc8-6d0e716555b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562d6e7e913e4f8d8f1f98be1362bf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 50 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc87465455b2498c9a198389b83c4538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='pos', style=ButtonStyle()), Button(description='neg', style=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f9c986c9b14a68859edae2741d2992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "annotations = Annotation.run_annotation(random_blm_data,labels,'modeling_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "049cc636-2a1b-4826-8771-819889ecbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data['label'] = annotations['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d40ebdb-f900-4ea9-921c-3968c87de136",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data = pd.read_csv('/projects/academic/kjoseph/zijian/negative_tweet_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb17140-a33d-453b-8d9c-c463ee895e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_ids = validate_data['rt_id'].tolist()\n",
    "rt_ids_str = ', '.join([str(id) for id in rt_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5a5775a-761e-4444-89e1-9f5f5d92bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {ori_table_name} WHERE rt_id IN ({rt_ids_str}) ORDER BY RAND() LIMIT 200;\"\n",
    "neg_vali = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7820e36-c726-45e6-814d-832441b6ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {ori_table_name} WHERE rt_id NOT IN ({rt_ids_str}) ORDER BY RAND() LIMIT 200;\"\n",
    "pos_vali = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7aa14fc-27fa-4c77-942d-3da67797c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_vali['label'] = 'neg'\n",
    "pos_vali['label'] = 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d975e401-2770-47ff-a41f-b0e7b829e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data_vali = pd.concat([neg_vali,pos_vali]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c693d8-d198-49ad-9ee8-e60663b2e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vali_per = 0.4\n",
    "# random_blm_data_vali = random_blm_data.groupby('label').apply(lambda x: x.sample(frac=vali_per, random_state=42)).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f52fd7b6-97d6-4b99-b841-d2bd7c7da16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(random_blm_data[random_blm_data['label'].isin(['neg','pos'])][['modeling_text','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d842b92-b3a4-4e00-846c-e389f510ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': dataset  # Set the 'train' split\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9243256f-8bd2-4202-9742-53a96c82f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['validation'] = Dataset.from_pandas(random_blm_data_vali[['modeling_text','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "134ea984-d3c5-4fbf-a258-f314f65cba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f4b1de5-d4bd-44bc-92aa-f70cedb08e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/academic/kjoseph/zijian/zijianan_'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d8601-6c67-4441-b771-d828ad1f471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "/projects/academic/kjoseph/zijian/zijianan_blm_random_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "076e290a-cdff-436b-a2cd-f2ec51ef24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = save_path + \"blm_random_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c2ead9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43cae4f4-5401-474f-9e69-65573f994ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[WARNING|integration_utils.py:82] 2024-05-13 15:54:07,244 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2024 15:54:07 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 2distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[WARNING|modeling_utils.py:4172] 2024-05-13 15:54:11,151 >> Some weights of RobertaModel were not initialized from the model checkpoint at launch/POLITICS and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c8a932395f4a798fc1921a4722831e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/29 [00:00<?, ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92efb6a622934ecfad22f71c7e3f0796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf2ad7193264cd38a2c4442430f901f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6dbabe413942f8bca79d9cd974cd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ff0b71abe44aeda3bf6ae5ff382a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c43a807e1f4c7a97aa3164f3219512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/pytorch/1.13.1-CUDA-11.8.0/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "[WARNING|modeling_utils.py:1188] 2024-05-13 15:54:21,241 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =      4.015\n",
      "  train_runtime            = 0:00:04.97\n",
      "  train_samples            =         29\n",
      "  train_samples_per_second =     58.298\n",
      "  train_steps_per_second   =       2.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =     0.5475\n",
      "  eval_loss               =      5.442\n",
      "  eval_runtime            = 0:00:01.04\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    383.723\n",
      "  eval_steps_per_second   =      6.715\n",
      "{'eval_loss': 5.441959857940674, 'eval_accuracy': 0.5475, 'eval_runtime': 1.0424, 'eval_samples_per_second': 383.723, 'eval_steps_per_second': 6.715, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 54.8%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_instance = ModelTraining(dataset=dataset, \\\n",
    "                                  model_name_or_path='launch/POLITICS', \\\n",
    "                                  label_column_name='label', \\\n",
    "                                  text_column_name='modeling_text',\\\n",
    "                                  save_path=save_path, \\\n",
    "                                  num_train_epochs=10)\n",
    "model_0 = training_instance.train_model()\n",
    "model_0.to('cpu')\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553f28e-c538-41bf-90f2-a3baec76db0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d29ba8c-959d-4b8f-a13b-663be917ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query = f'''\n",
    "# SELECT * FROM {ori_table_name} ORDER BY RAND() LIMIT 1000;\n",
    "# '''\n",
    "# inference_data = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e06be579-e027-49bc-a81c-49c99fab628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = random_blm_data_vali.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a5d874c-83b5-4a0e-bcba-336c3cd55dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/projects/academic/kjoseph/zijian/zijianan_blm_random_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76bebc56-7bef-42ce-8ad6-e2546f5229de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3c056cabf54f058be86f881644e205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11ad668726e43b68a90daf916db8cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb548cfeeaf7446ab2cc37630141bd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44335ce0c7ad4e23972236d78d0e6fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339f67b175c1469ba2471b0d2d0fa989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-13 15:55:25,544 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n"
     ]
    }
   ],
   "source": [
    "active_learning_instance = ActiveLearning(model_name_or_path=save_path, \\\n",
    "                                  label_column_name='label', \\\n",
    "                                  text_column_name='modeling_text',\\\n",
    "                                  theta=10,\n",
    "                                  i=3,\n",
    "                                  vali_data=dataset[\"validation\"],\n",
    "                                  inference_datasets=inference_data,\n",
    "                                  tokenizer_name='roberta-large',\n",
    "                                  uname=uname,\n",
    "                                  labels=['neg','pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed202b1-13c6-46d4-a508-b9c194de02f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-13 15:55:29,468 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
      "Processing batches:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:04<00:01,  2.15it/s][WARNING|logging.py:329] 2024-05-13 15:55:34,123 >> You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Processing batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:05<00:00,  2.24it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d86fd0ca91b424e8a5410c953be5533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a3666540e64b2f892d549b34927673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='neg', style=ButtonStyle()), Button(description='pos', style=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb28dc7b9f54edea8b1f0819f700cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|integration_utils.py:82] 2024-05-13 15:55:38,008 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2024 15:55:38 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 2distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7117ed390d35479b92c830511e2dd255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/10 [00:00<?, ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58d55a3acd44511b5ade80c4f71c579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce3238924984b169689ec77ccb8d09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027cbeb696f84bb0842f5b1733fa7dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6c2d423c574a849aaedbd9d807ff90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8312cb1fc834461dbabb8b26b3c6be66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/pytorch/1.13.1-CUDA-11.8.0/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "[WARNING|modeling_utils.py:1188] 2024-05-13 15:55:47,218 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     2.9936\n",
      "  train_runtime            = 0:00:02.08\n",
      "  train_samples            =         10\n",
      "  train_samples_per_second =     47.889\n",
      "  train_steps_per_second   =      4.789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =      0.505\n",
      "  eval_loss               =     5.1015\n",
      "  eval_runtime            = 0:00:00.94\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    421.282\n",
      "  eval_steps_per_second   =      7.372\n",
      "{'eval_loss': 5.1015143394470215, 'eval_accuracy': 0.505, 'eval_runtime': 0.9495, 'eval_samples_per_second': 421.282, 'eval_steps_per_second': 7.372, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 50.5%\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-13 15:55:53,260 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
      "Processing batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:05<00:00,  2.28it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e7fdf99b944a0db66a7d5bfe037010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffe373636c943318420617cb26d911c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='neg', style=ButtonStyle()), Button(description='pos', style=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0610ee8477114d049d3983cce5242e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = active_learning_instance.perform_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f558f-2474-4307-85d8-5e4e826cc860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
