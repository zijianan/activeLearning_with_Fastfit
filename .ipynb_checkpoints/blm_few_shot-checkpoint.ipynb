{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f8b6c9-c3b3-40e5-b867-30a6c85b3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_annotator_with_hint import MySQLDataHandler, Annotation, ModelTraining, ActiveLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c16efa-d1ab-4696-969a-16b7107b9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Features, Value,load_dataset,DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8dffe2-ae95-496a-8ec2-4b3db9ff394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7aa3a6-e358-4b2c-b5ac-bc40ba286d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "uname = 'zijianan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16f2332-fe47-4b71-a841-c9d57b76cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_table_name = 'blm_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e7775f-3293-4892-9b82-a3573be572c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_annotated_table_name = 'blm_annotated_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "974bba83-c682-436c-a866-14672ed16aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_handler = MySQLDataHandler('localhost', 'zijianan', '12Q3qeqs,', '5_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c58d38d-bca8-4d4e-aff9-677430be273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/data/blm_model/'+uname+'_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9fe5e2-aedc-45b7-bfc5-e5931c1f7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['pos','neg','unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1e191-2322-4bdd-ac79-764f65437aaa",
   "metadata": {},
   "source": [
    "### random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd0a267-8321-4fae-87e1-28eea6c20f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "SELECT * FROM {ori_table_name} ORDER BY RAND() LIMIT 50;\n",
    "'''\n",
    "random_blm_data = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1a6e483-59b7-4c37-88d9-4f26806535d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rt_id</th>\n",
       "      <th>rt_uid</th>\n",
       "      <th>modeling_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1902521</td>\n",
       "      <td>1095518845438054400</td>\n",
       "      <td>3259117872</td>\n",
       "      <td>#lapd officer needs help. suspect is trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1099134</td>\n",
       "      <td>1266402639308296192</td>\n",
       "      <td>49800332</td>\n",
       "      <td>nobody gives a shit what racist birther melani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>839208</td>\n",
       "      <td>1319462787337252865</td>\n",
       "      <td>2779389582</td>\n",
       "      <td>here are the facts on law &amp;amp; order and raci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177909</td>\n",
       "      <td>1587553926102110213</td>\n",
       "      <td>832616065259614209</td>\n",
       "      <td>donald trump really didn’t want to be presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3697118</td>\n",
       "      <td>1491859465574002693</td>\n",
       "      <td>328756439</td>\n",
       "      <td>america was complacent during the 2016 electio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3685442</td>\n",
       "      <td>1325529789520809991</td>\n",
       "      <td>5741722</td>\n",
       "      <td>president-elect joe biden and vice president-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>787345</td>\n",
       "      <td>1569532274810716162</td>\n",
       "      <td>2835451658</td>\n",
       "      <td>the union representing firefighters in portlan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3611012</td>\n",
       "      <td>1278136918581051392</td>\n",
       "      <td>760093504894894080</td>\n",
       "      <td>so are we gonna get back to why #blacklivesmat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2559175</td>\n",
       "      <td>624079158277185536</td>\n",
       "      <td>15907183</td>\n",
       "      <td>the police found this person threatening. this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1248596</td>\n",
       "      <td>1354129632484859906</td>\n",
       "      <td>1275285589818998786</td>\n",
       "      <td>officer sicknick died defending senate republi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4197024</td>\n",
       "      <td>931519184470708224</td>\n",
       "      <td>883619466</td>\n",
       "      <td>exposing men behaving badly in private setting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3892031</td>\n",
       "      <td>1364674231393468416</td>\n",
       "      <td>310677505</td>\n",
       "      <td>if i wanted to prove that young trans men were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2220959</td>\n",
       "      <td>681606068615667712</td>\n",
       "      <td>570324680</td>\n",
       "      <td>“yonder they do not love your flesh. they desp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3686034</td>\n",
       "      <td>1336642872171487232</td>\n",
       "      <td>467774585</td>\n",
       "      <td>a web of callousness and corruption. read this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4336185</td>\n",
       "      <td>978409070917906432</td>\n",
       "      <td>115705583</td>\n",
       "      <td>it’s not just the hills that are green in this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1691545</td>\n",
       "      <td>969663138445578242</td>\n",
       "      <td>523447678</td>\n",
       "      <td>my gay ass trying to socialize in family gathe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2603545</td>\n",
       "      <td>1355730194112327680</td>\n",
       "      <td>471512389</td>\n",
       "      <td>tips for donating plasma while trans: they onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1619460</td>\n",
       "      <td>901528128203444225</td>\n",
       "      <td>108140114</td>\n",
       "      <td>facebook nowadays:\\nautoplay video\\nautoplay v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>611151</td>\n",
       "      <td>1009435217952681988</td>\n",
       "      <td>1917731</td>\n",
       "      <td>just in: texas officials grant permission for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1112751</td>\n",
       "      <td>1352279683052744707</td>\n",
       "      <td>713752653289955329</td>\n",
       "      <td>if you’re offended by a call to end white supr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3995529</td>\n",
       "      <td>955275989730430976</td>\n",
       "      <td>810698204375293953</td>\n",
       "      <td>1%of whites were slave owners at the height of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>534838</td>\n",
       "      <td>877576023046488064</td>\n",
       "      <td>241316195</td>\n",
       "      <td>was this road rage? was this a lone wolf? was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4070435</td>\n",
       "      <td>1067553282443247616</td>\n",
       "      <td>20458149</td>\n",
       "      <td>when @gregmclean92 came out as gay... \\n\\n\"eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1706262</td>\n",
       "      <td>1230484230142074880</td>\n",
       "      <td>961930212656275456</td>\n",
       "      <td>our thoughts and support are with all those wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3602634</td>\n",
       "      <td>1201509081304854528</td>\n",
       "      <td>40623989</td>\n",
       "      <td>because of desperate poverty or truly horrific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1689518</td>\n",
       "      <td>937665935456063488</td>\n",
       "      <td>4165642155</td>\n",
       "      <td>.@alandersh on @foxandfriends: you cannot char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2402443</td>\n",
       "      <td>1380865339127382018</td>\n",
       "      <td>1596923732</td>\n",
       "      <td>where are all of the lgbtq+ orgs right now? wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1481468</td>\n",
       "      <td>852612432635846657</td>\n",
       "      <td>31135856</td>\n",
       "      <td>close the gay torture camps in #chechnya! sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2598433</td>\n",
       "      <td>1302624718286135298</td>\n",
       "      <td>1092037021432897537</td>\n",
       "      <td>so are we going to take our country back yet o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2666426</td>\n",
       "      <td>1303456751950336000</td>\n",
       "      <td>18584875</td>\n",
       "      <td>black lives matter protesters scream at elderl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2802610</td>\n",
       "      <td>1306647647474851840</td>\n",
       "      <td>66054233</td>\n",
       "      <td>i wonder how many white guys cops shot this ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2997795</td>\n",
       "      <td>1268006244461117441</td>\n",
       "      <td>1037321378</td>\n",
       "      <td>taking a knee\\nbecause of a failed justice sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1422253</td>\n",
       "      <td>989282685993578496</td>\n",
       "      <td>3284112337</td>\n",
       "      <td>wow: after kanye sends democrats panicking, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2173444</td>\n",
       "      <td>1091390869536555009</td>\n",
       "      <td>250482344</td>\n",
       "      <td>teachers, y’all ready with your antiracist les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>430278</td>\n",
       "      <td>1299727336313585669</td>\n",
       "      <td>442532487</td>\n",
       "      <td>no one remembers gaza until there's violence. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2335378</td>\n",
       "      <td>1387856695142100999</td>\n",
       "      <td>102417993</td>\n",
       "      <td>one thing i hope young people learn is that tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4432978</td>\n",
       "      <td>1340667243051532288</td>\n",
       "      <td>356408677</td>\n",
       "      <td>beyond \"defund the police\"...\\n\\nfacing square...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3571025</td>\n",
       "      <td>421365388186640385</td>\n",
       "      <td>282695161</td>\n",
       "      <td>i can't believe democrats are still lying to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1403486</td>\n",
       "      <td>481502091467563008</td>\n",
       "      <td>11859822</td>\n",
       "      <td>deuteronomy 15:7 – “if anyone is poor…do not b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1220980</td>\n",
       "      <td>1012499643396046849</td>\n",
       "      <td>234865212</td>\n",
       "      <td>never forget: jeff zucker normalized trump and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1273349</td>\n",
       "      <td>673673725900820480</td>\n",
       "      <td>379962842</td>\n",
       "      <td>now within days of america's largest terrorist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2338983</td>\n",
       "      <td>1446572880859369473</td>\n",
       "      <td>17278675</td>\n",
       "      <td>federal prosecutors say they won't file charge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2923957</td>\n",
       "      <td>1169639562928427008</td>\n",
       "      <td>22283200</td>\n",
       "      <td>dept of ed concludes investigations into michi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4226936</td>\n",
       "      <td>1318399335902576643</td>\n",
       "      <td>2602121875</td>\n",
       "      <td>while research shows that gen z women are even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3575702</td>\n",
       "      <td>624965777075109888</td>\n",
       "      <td>1496971</td>\n",
       "      <td>rest in peace: #sandrabland will be laid to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2774504</td>\n",
       "      <td>938224245192105984</td>\n",
       "      <td>4822119385</td>\n",
       "      <td>sweet home alabama!\\n\\na white supremacist ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1059499</td>\n",
       "      <td>1622947864409255937</td>\n",
       "      <td>2768346873</td>\n",
       "      <td>blowing up balloon now woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>690444</td>\n",
       "      <td>1215575298239893504</td>\n",
       "      <td>725064846056640512</td>\n",
       "      <td>geraldo got a well deserved spankin by @dbongi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>835655</td>\n",
       "      <td>1293291436222210048</td>\n",
       "      <td>1025609000954474496</td>\n",
       "      <td>kamala harris then believed:\\n\\n- joe biden's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>545349</td>\n",
       "      <td>1035911117984284673</td>\n",
       "      <td>1008061</td>\n",
       "      <td>hey, portlanders, 22 of our local faith leader...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                rt_id               rt_uid  \\\n",
       "0   1902521  1095518845438054400           3259117872   \n",
       "1   1099134  1266402639308296192             49800332   \n",
       "2    839208  1319462787337252865           2779389582   \n",
       "3    177909  1587553926102110213   832616065259614209   \n",
       "4   3697118  1491859465574002693            328756439   \n",
       "5   3685442  1325529789520809991              5741722   \n",
       "6    787345  1569532274810716162           2835451658   \n",
       "7   3611012  1278136918581051392   760093504894894080   \n",
       "8   2559175   624079158277185536             15907183   \n",
       "9   1248596  1354129632484859906  1275285589818998786   \n",
       "10  4197024   931519184470708224            883619466   \n",
       "11  3892031  1364674231393468416            310677505   \n",
       "12  2220959   681606068615667712            570324680   \n",
       "13  3686034  1336642872171487232            467774585   \n",
       "14  4336185   978409070917906432            115705583   \n",
       "15  1691545   969663138445578242            523447678   \n",
       "16  2603545  1355730194112327680            471512389   \n",
       "17  1619460   901528128203444225            108140114   \n",
       "18   611151  1009435217952681988              1917731   \n",
       "19  1112751  1352279683052744707   713752653289955329   \n",
       "20  3995529   955275989730430976   810698204375293953   \n",
       "21   534838   877576023046488064            241316195   \n",
       "22  4070435  1067553282443247616             20458149   \n",
       "23  1706262  1230484230142074880   961930212656275456   \n",
       "24  3602634  1201509081304854528             40623989   \n",
       "25  1689518   937665935456063488           4165642155   \n",
       "26  2402443  1380865339127382018           1596923732   \n",
       "27  1481468   852612432635846657             31135856   \n",
       "28  2598433  1302624718286135298  1092037021432897537   \n",
       "29  2666426  1303456751950336000             18584875   \n",
       "30  2802610  1306647647474851840             66054233   \n",
       "31  2997795  1268006244461117441           1037321378   \n",
       "32  1422253   989282685993578496           3284112337   \n",
       "33  2173444  1091390869536555009            250482344   \n",
       "34   430278  1299727336313585669            442532487   \n",
       "35  2335378  1387856695142100999            102417993   \n",
       "36  4432978  1340667243051532288            356408677   \n",
       "37  3571025   421365388186640385            282695161   \n",
       "38  1403486   481502091467563008             11859822   \n",
       "39  1220980  1012499643396046849            234865212   \n",
       "40  1273349   673673725900820480            379962842   \n",
       "41  2338983  1446572880859369473             17278675   \n",
       "42  2923957  1169639562928427008             22283200   \n",
       "43  4226936  1318399335902576643           2602121875   \n",
       "44  3575702   624965777075109888              1496971   \n",
       "45  2774504   938224245192105984           4822119385   \n",
       "46  1059499  1622947864409255937           2768346873   \n",
       "47   690444  1215575298239893504   725064846056640512   \n",
       "48   835655  1293291436222210048  1025609000954474496   \n",
       "49   545349  1035911117984284673              1008061   \n",
       "\n",
       "                                        modeling_text  \n",
       "0   #lapd officer needs help. suspect is trying to...  \n",
       "1   nobody gives a shit what racist birther melani...  \n",
       "2   here are the facts on law &amp; order and raci...  \n",
       "3   donald trump really didn’t want to be presiden...  \n",
       "4   america was complacent during the 2016 electio...  \n",
       "5   president-elect joe biden and vice president-e...  \n",
       "6   the union representing firefighters in portlan...  \n",
       "7   so are we gonna get back to why #blacklivesmat...  \n",
       "8   the police found this person threatening. this...  \n",
       "9   officer sicknick died defending senate republi...  \n",
       "10  exposing men behaving badly in private setting...  \n",
       "11  if i wanted to prove that young trans men were...  \n",
       "12  “yonder they do not love your flesh. they desp...  \n",
       "13  a web of callousness and corruption. read this...  \n",
       "14  it’s not just the hills that are green in this...  \n",
       "15  my gay ass trying to socialize in family gathe...  \n",
       "16  tips for donating plasma while trans: they onl...  \n",
       "17  facebook nowadays:\\nautoplay video\\nautoplay v...  \n",
       "18  just in: texas officials grant permission for ...  \n",
       "19  if you’re offended by a call to end white supr...  \n",
       "20  1%of whites were slave owners at the height of...  \n",
       "21  was this road rage? was this a lone wolf? was ...  \n",
       "22  when @gregmclean92 came out as gay... \\n\\n\"eve...  \n",
       "23  our thoughts and support are with all those wh...  \n",
       "24  because of desperate poverty or truly horrific...  \n",
       "25  .@alandersh on @foxandfriends: you cannot char...  \n",
       "26  where are all of the lgbtq+ orgs right now? wh...  \n",
       "27  close the gay torture camps in #chechnya! sign...  \n",
       "28  so are we going to take our country back yet o...  \n",
       "29  black lives matter protesters scream at elderl...  \n",
       "30  i wonder how many white guys cops shot this ye...  \n",
       "31  taking a knee\\nbecause of a failed justice sys...  \n",
       "32  wow: after kanye sends democrats panicking, ch...  \n",
       "33  teachers, y’all ready with your antiracist les...  \n",
       "34  no one remembers gaza until there's violence. ...  \n",
       "35  one thing i hope young people learn is that tr...  \n",
       "36  beyond \"defund the police\"...\\n\\nfacing square...  \n",
       "37  i can't believe democrats are still lying to a...  \n",
       "38  deuteronomy 15:7 – “if anyone is poor…do not b...  \n",
       "39  never forget: jeff zucker normalized trump and...  \n",
       "40  now within days of america's largest terrorist...  \n",
       "41  federal prosecutors say they won't file charge...  \n",
       "42  dept of ed concludes investigations into michi...  \n",
       "43  while research shows that gen z women are even...  \n",
       "44  rest in peace: #sandrabland will be laid to re...  \n",
       "45  sweet home alabama!\\n\\na white supremacist ste...  \n",
       "46                       blowing up balloon now woke   \n",
       "47  geraldo got a well deserved spankin by @dbongi...  \n",
       "48  kamala harris then believed:\\n\\n- joe biden's ...  \n",
       "49  hey, portlanders, 22 of our local faith leader...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_blm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba6d2635-f7ac-43da-acc8-6d0e716555b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98f81e1d2b34a10802f4d3cf594a569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 50 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181c6934c885402e8334e846f75c8104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='pos', style=ButtonStyle()), Button(description='neg', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89d559c30f045d79bfe238ba0bdc7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "annotations = Annotation.run_annotation(random_blm_data,labels,'modeling_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "049cc636-2a1b-4826-8771-819889ecbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data['label'] = annotations['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b962efe-9af6-4117-9185-378106b8cb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "642546e8-df5f-4b84-9301-53bf10b483f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data = pd.read_csv('blm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d40ebdb-f900-4ea9-921c-3968c87de136",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data = pd.read_csv('/data/zijian/negative_tweet_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb17140-a33d-453b-8d9c-c463ee895e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_ids = validate_data['rt_id'].tolist()\n",
    "rt_ids_str = ', '.join([str(id) for id in rt_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5a5775a-761e-4444-89e1-9f5f5d92bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {ori_table_name} WHERE rt_id IN ({rt_ids_str}) ORDER BY RAND() LIMIT 200;\"\n",
    "neg_vali = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7820e36-c726-45e6-814d-832441b6ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {ori_table_name} WHERE rt_id NOT IN ({rt_ids_str}) ORDER BY RAND() LIMIT 200;\"\n",
    "pos_vali = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7aa14fc-27fa-4c77-942d-3da67797c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_vali['label'] = 'neg'\n",
    "pos_vali['label'] = 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d975e401-2770-47ff-a41f-b0e7b829e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data_vali = pd.concat([neg_vali,pos_vali]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c693d8-d198-49ad-9ee8-e60663b2e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vali_per = 0.4\n",
    "# random_blm_data_vali = random_blm_data.groupby('label').apply(lambda x: x.sample(frac=vali_per, random_state=42)).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f52fd7b6-97d6-4b99-b841-d2bd7c7da16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(random_blm_data[random_blm_data['label'].isin(['neg','pos'])][['modeling_text','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d842b92-b3a4-4e00-846c-e389f510ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': dataset  # Set the 'train' split\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9243256f-8bd2-4202-9742-53a96c82f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['validation'] = Dataset.from_pandas(random_blm_data_vali[['modeling_text','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "134ea984-d3c5-4fbf-a258-f314f65cba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f4b1de5-d4bd-44bc-92aa-f70cedb08e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/blm_model/zijianan_'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "076e290a-cdff-436b-a2cd-f2ec51ef24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = save_path + \"blm_random_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43cae4f4-5401-474f-9e69-65573f994ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:50:30 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:4172] 2024-05-08 10:50:31,529 >> Some weights of RobertaModel were not initialized from the model checkpoint at launch/POLITICS and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae168c8c69754d3b848108192acb2461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/29 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71f8257630b4d84b68126ae72ff6eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caa04fc33be4cb5a3ed07791facd731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93077cd1d5246fcbd2bd86333631ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e631408d1c464aac827856b2a724ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a3fce0afc4469c847b81cdbabbf6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zijianan/miniconda3/envs/fu/lib/python3.9/site-packages/fastfit/train.py:878: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(self.data_args.metric_name)\n",
      "/home/zijianan/miniconda3/envs/fu/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:50:39 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:50:41 - ERROR - wandb.jupyter - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzijianan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/zijianan/wandb/run-20240508_105042-qqjodq62</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zijianan/huggingface/runs/qqjodq62/workspace' target=\"_blank\">northern-terrain-40</a></strong> to <a href='https://wandb.ai/zijianan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zijianan/huggingface' target=\"_blank\">https://wandb.ai/zijianan/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zijianan/huggingface/runs/qqjodq62/workspace' target=\"_blank\">https://wandb.ai/zijianan/huggingface/runs/qqjodq62/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:1188] 2024-05-08 10:50:53,246 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     3.9178\n",
      "  train_runtime            = 0:00:14.57\n",
      "  train_samples            =         29\n",
      "  train_samples_per_second =     19.904\n",
      "  train_steps_per_second   =      1.373\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =     0.5325\n",
      "  eval_loss               =     5.9804\n",
      "  eval_runtime            = 0:00:00.82\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    486.078\n",
      "  eval_steps_per_second   =     15.798\n",
      "{'eval_loss': 5.980385780334473, 'eval_accuracy': 0.5325, 'eval_runtime': 0.8229, 'eval_samples_per_second': 486.078, 'eval_steps_per_second': 15.798, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 53.2%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_instance = ModelTraining(dataset=dataset, \\\n",
    "                                  model_name_or_path='launch/POLITICS', \\\n",
    "                                  label_column_name='label', \\\n",
    "                                  text_column_name='modeling_text',\\\n",
    "                                  save_path=save_path, \\\n",
    "                                  num_train_epochs=10)\n",
    "model_0 = training_instance.train_model()\n",
    "model_0.to('cpu')\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553f28e-c538-41bf-90f2-a3baec76db0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d29ba8c-959d-4b8f-a13b-663be917ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query = f'''\n",
    "# SELECT * FROM {ori_table_name} ORDER BY RAND() LIMIT 1000;\n",
    "# '''\n",
    "# inference_data = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e06be579-e027-49bc-a81c-49c99fab628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = random_blm_data_vali.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a5d874c-83b5-4a0e-bcba-336c3cd55dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/data/blm_model/zijianan_blm_random_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76bebc56-7bef-42ce-8ad6-e2546f5229de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-08 11:15:55,104 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n"
     ]
    }
   ],
   "source": [
    "active_learning_instance = ActiveLearning(model_name_or_path=save_path, \\\n",
    "                                  label_column_name='label', \\\n",
    "                                  text_column_name='modeling_text',\\\n",
    "                                  theta=10,\n",
    "                                  i=3,\n",
    "                                  vali_data=dataset[\"validation\"],\n",
    "                                  inference_datasets=inference_data,\n",
    "                                  tokenizer_name='roberta-large',\n",
    "                                  uname=uname,\n",
    "                                  labels=['neg','pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ed202b1-13c6-46d4-a508-b9c194de02f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-08 10:51:32,917 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
      "Processing batches:  77%|███████▋  | 10/13 [00:06<00:01,  1.66it/s][WARNING|logging.py:329] 2024-05-08 10:51:38,974 >> You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Processing batches: 100%|██████████| 13/13 [00:07<00:00,  1.72it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0281916af9cf4b3bb83c7dbfc9e20e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e1433fb06649488f5c923cd96289d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='neg', style=ButtonStyle()), Button(description='pos', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cb59bd17e54261b7c04c7459ca59c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:51:52 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87b6cd99d90490aaa9bb4db12a3362a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/10 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca30d621e8ff43c3aaf0b2e92c6af495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff88e3244df74fb1ae0a629a3e87ee7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dab780edbea401baf3ca542a5a7c4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edcd4fdc2834ef8b28487d9369371cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef865a0b600744c8ba6ec72899264476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:52:01 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zijianan/miniconda3/envs/fu/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[WARNING|modeling_utils.py:1188] 2024-05-08 10:52:02,399 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     3.5136\n",
      "  train_runtime            = 0:00:01.40\n",
      "  train_samples            =         10\n",
      "  train_samples_per_second =     71.229\n",
      "  train_steps_per_second   =      7.123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =      0.535\n",
      "  eval_loss               =     5.8452\n",
      "  eval_runtime            = 0:00:00.77\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    516.537\n",
      "  eval_steps_per_second   =     16.787\n",
      "{'eval_loss': 5.845210075378418, 'eval_accuracy': 0.535, 'eval_runtime': 0.7744, 'eval_samples_per_second': 516.537, 'eval_steps_per_second': 16.787, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 53.5%\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-08 10:52:07,258 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
      "Processing batches: 100%|██████████| 13/13 [00:07<00:00,  1.73it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d880c2592343359abde972f976966d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f762ddbc424cdb97d5d0ad42400a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='neg', style=ButtonStyle()), Button(description='pos', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e8c19dd5a5450488cc78174ad2fc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:52:21 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5f138271414d1394910036f8596fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/10 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f92ae877bd4b82bb4071b49ce97ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f3c360bd084bc7b8f59946d6a6cec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6abb3445ad45708d50b030d3225c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd17face2bc46eda559e43f6dd89683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604ad4cdb08b4c1e935ffd370e234515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:52:31 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zijianan/miniconda3/envs/fu/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[WARNING|modeling_utils.py:1188] 2024-05-08 10:52:31,701 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     3.2465\n",
      "  train_runtime            = 0:00:01.45\n",
      "  train_samples            =         10\n",
      "  train_samples_per_second =     68.526\n",
      "  train_steps_per_second   =      6.853\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =     0.5375\n",
      "  eval_loss               =     6.5403\n",
      "  eval_runtime            = 0:00:00.82\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    485.543\n",
      "  eval_steps_per_second   =      15.78\n",
      "{'eval_loss': 6.540343761444092, 'eval_accuracy': 0.5375, 'eval_runtime': 0.8238, 'eval_samples_per_second': 485.543, 'eval_steps_per_second': 15.78, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 53.8%\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-08 10:52:36,624 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
      "Processing batches: 100%|██████████| 13/13 [00:07<00:00,  1.72it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a66ae25159401c9da99686a7c2d26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3c70374646469bba73a96fb30602db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='neg', style=ButtonStyle()), Button(description='pos', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc3854d7623464fae853b54fc9122d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:52:50 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f514bb0b98416da42d5b80b672c353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/10 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec20215a0b3465cadc677d17a50897c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db9986dbe614b928342db4a909c1331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d414b2ce991c4b399b7d0865648f6e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c18e726558481494592fcf9c6e2db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea0e714caef407a9d0b670db956ed2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:53:00 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zijianan/miniconda3/envs/fu/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[WARNING|modeling_utils.py:1188] 2024-05-08 10:53:00,728 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     3.4587\n",
      "  train_runtime            = 0:00:01.39\n",
      "  train_samples            =         10\n",
      "  train_samples_per_second =     71.442\n",
      "  train_steps_per_second   =      7.144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =     0.5275\n",
      "  eval_loss               =     6.5381\n",
      "  eval_runtime            = 0:00:00.80\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    496.641\n",
      "  eval_steps_per_second   =     16.141\n",
      "{'eval_loss': 6.5380859375, 'eval_accuracy': 0.5275, 'eval_runtime': 0.8054, 'eval_samples_per_second': 496.641, 'eval_steps_per_second': 16.141, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 52.8%\n"
     ]
    }
   ],
   "source": [
    "t1 = active_learning_instance.perform_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f558f-2474-4307-85d8-5e4e826cc860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_fu",
   "language": "python",
   "name": "test_fu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
