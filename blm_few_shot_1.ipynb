{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f8b6c9-c3b3-40e5-b867-30a6c85b3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_annotator_with_hint import MySQLDataHandler, Annotation, ModelTraining, ActiveLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c16efa-d1ab-4696-969a-16b7107b9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Features, Value,load_dataset,DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8dffe2-ae95-496a-8ec2-4b3db9ff394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7aa3a6-e358-4b2c-b5ac-bc40ba286d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "uname = 'zijianan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16f2332-fe47-4b71-a841-c9d57b76cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_table_name = 'blm_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e7775f-3293-4892-9b82-a3573be572c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_annotated_table_name = 'blm_annotated_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "974bba83-c682-436c-a866-14672ed16aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_handler = MySQLDataHandler('localhost', 'zijianan', '#######', '5_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c58d38d-bca8-4d4e-aff9-677430be273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/projects/academic/kjoseph/zijian/'+uname+'_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9fe5e2-aedc-45b7-bfc5-e5931c1f7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['pos','neg','unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1e191-2322-4bdd-ac79-764f65437aaa",
   "metadata": {},
   "source": [
    "### random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd0a267-8321-4fae-87e1-28eea6c20f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "SELECT * FROM {ori_table_name} ORDER BY RAND() LIMIT 50;\n",
    "'''\n",
    "random_blm_data = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1a6e483-59b7-4c37-88d9-4f26806535d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rt_id</th>\n",
       "      <th>rt_uid</th>\n",
       "      <th>modeling_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327408</td>\n",
       "      <td>763915332431941632</td>\n",
       "      <td>347627434</td>\n",
       "      <td>so wrong\\nnfl denies dallas cowboys’ req to ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>426399</td>\n",
       "      <td>1275114784787247104</td>\n",
       "      <td>47839801</td>\n",
       "      <td>get in losers, we’re dismantling the patriarchy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3544479</td>\n",
       "      <td>1284228067561558018</td>\n",
       "      <td>932630991298007041</td>\n",
       "      <td>the us equity markets = absolute units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>838469</td>\n",
       "      <td>1311615252748996608</td>\n",
       "      <td>16041234</td>\n",
       "      <td>trump administration instructed law enforcemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3229052</td>\n",
       "      <td>1656723610743222273</td>\n",
       "      <td>55060090</td>\n",
       "      <td>mitt romney condemns trump for offering pardon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4331812</td>\n",
       "      <td>909880965475868672</td>\n",
       "      <td>22637974</td>\n",
       "      <td>yale joins list of universities replacing \"fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>723406</td>\n",
       "      <td>1670135823684059137</td>\n",
       "      <td>55330244</td>\n",
       "      <td>nova scotia police thwart 3 arson attacks as m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>976267</td>\n",
       "      <td>1348348496018104322</td>\n",
       "      <td>1201348645225930752</td>\n",
       "      <td>the maga cult terrorists are vowing to return ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>507700</td>\n",
       "      <td>1399007405468532743</td>\n",
       "      <td>170254080</td>\n",
       "      <td>after the “socialist”-branded no evil foods bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3705769</td>\n",
       "      <td>301531740466470912</td>\n",
       "      <td>14752085</td>\n",
       "      <td>rt @michaelianblack: pay the people who write ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3460922</td>\n",
       "      <td>1068750114712371200</td>\n",
       "      <td>437737633</td>\n",
       "      <td>always loved this george h.w. bush moment from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2622734</td>\n",
       "      <td>441933742211203072</td>\n",
       "      <td>469194846</td>\n",
       "      <td>'race card transaction successful': larry elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2462461</td>\n",
       "      <td>1299552420264112130</td>\n",
       "      <td>2941665345</td>\n",
       "      <td>cops stop out-of-state caravan, arrest 9 heade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1598089</td>\n",
       "      <td>1535032524870758402</td>\n",
       "      <td>27789999</td>\n",
       "      <td>methodist leaders say 'rebellion and dysfuncti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4346423</td>\n",
       "      <td>1151177118329573376</td>\n",
       "      <td>42958829</td>\n",
       "      <td>pres. trump has refused to walk back his racis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64432</td>\n",
       "      <td>938558907475095552</td>\n",
       "      <td>2729061</td>\n",
       "      <td>a free sf anthology about space travel, inequa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>184537</td>\n",
       "      <td>500738818493128704</td>\n",
       "      <td>89887215</td>\n",
       "      <td>nixon says he has signed a state of emergency ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3084287</td>\n",
       "      <td>1439587622406533120</td>\n",
       "      <td>624210678</td>\n",
       "      <td>omg i just realized that all we need to do to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1863171</td>\n",
       "      <td>1420679211354927104</td>\n",
       "      <td>328756439</td>\n",
       "      <td>house gop leader kevin mccarthy is re-writing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3018550</td>\n",
       "      <td>1471347050952409089</td>\n",
       "      <td>15515169</td>\n",
       "      <td>breaking: nypd arresting unvaxxed diners at ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>429854</td>\n",
       "      <td>1298348675765329920</td>\n",
       "      <td>443350004</td>\n",
       "      <td>if you think critical race studies is a threat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2616162</td>\n",
       "      <td>1565017812367773696</td>\n",
       "      <td>781982295863484456</td>\n",
       "      <td>“one thing about black people is we don’t wait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2812065</td>\n",
       "      <td>1408469168547053573</td>\n",
       "      <td>285852662</td>\n",
       "      <td>tamir rice would’ve been 19 years old today. t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3484304</td>\n",
       "      <td>1350107733907955713</td>\n",
       "      <td>787935427961446400</td>\n",
       "      <td>feds edge closer to sedition charge in #capito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>169251</td>\n",
       "      <td>1404959730620145682</td>\n",
       "      <td>21103426</td>\n",
       "      <td>i have mixed feelings about making juneteenth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>445804</td>\n",
       "      <td>1505999197564141569</td>\n",
       "      <td>819034558058229760</td>\n",
       "      <td>i barely saw any asians in the ncaa tournament...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2319892</td>\n",
       "      <td>1268364850822029325</td>\n",
       "      <td>252398355</td>\n",
       "      <td>the right to riot shall not be infringed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3363394</td>\n",
       "      <td>1621263614849204226</td>\n",
       "      <td>3066800573</td>\n",
       "      <td>scoop: florida state university has adopted a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2808890</td>\n",
       "      <td>1374820817259831305</td>\n",
       "      <td>22650211</td>\n",
       "      <td>sesame workshop, the organization behind \"sesa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1427368</td>\n",
       "      <td>1067182446704242689</td>\n",
       "      <td>17494010</td>\n",
       "      <td>to celebrate this #cybermonday, it’s time we g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>479053</td>\n",
       "      <td>1058084733899333633</td>\n",
       "      <td>4581356534</td>\n",
       "      <td>i decided to #exit the democrat party. think f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1355533</td>\n",
       "      <td>1001259369562947584</td>\n",
       "      <td>2937613910</td>\n",
       "      <td>some “star” players are threatening to sit out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3542265</td>\n",
       "      <td>1273035148498362368</td>\n",
       "      <td>16005250</td>\n",
       "      <td>this card was spotted at a supermarket in germ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1810619</td>\n",
       "      <td>537098798372507648</td>\n",
       "      <td>27075032</td>\n",
       "      <td>image: rt @russptacek: #ferguson:  store in fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1242038</td>\n",
       "      <td>1293332620118577157</td>\n",
       "      <td>1079833198463467520</td>\n",
       "      <td>economic laws are not subject to a vote. they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>347071</td>\n",
       "      <td>1136059220325994496</td>\n",
       "      <td>270627293</td>\n",
       "      <td>theydies and gentlethems:\\non this, the fourth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1642891</td>\n",
       "      <td>1270037707834773504</td>\n",
       "      <td>2907975195</td>\n",
       "      <td>gen z will drink one medium caramel latte, not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1529777</td>\n",
       "      <td>1529589638075142152</td>\n",
       "      <td>1270742738946846720</td>\n",
       "      <td>.@prisonculture on the place of imagination an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3768541</td>\n",
       "      <td>1579185007020871680</td>\n",
       "      <td>23169735</td>\n",
       "      <td>disgusting anti-black racist comments from loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4123123</td>\n",
       "      <td>799030397380206592</td>\n",
       "      <td>45671898</td>\n",
       "      <td>actually said the answer to \"what happened\"? i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1763758</td>\n",
       "      <td>1037754885805166594</td>\n",
       "      <td>2962527299</td>\n",
       "      <td>gay culture is having to clarify the species o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3556568</td>\n",
       "      <td>1399779255085527045</td>\n",
       "      <td>20545835</td>\n",
       "      <td>rep. nancy mace's home in charleston, s.c., wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2537875</td>\n",
       "      <td>1380241583572934662</td>\n",
       "      <td>1331107444416770048</td>\n",
       "      <td>🐾 we love dr. martin tobin. that’s all. that’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1666440</td>\n",
       "      <td>1555228206499766272</td>\n",
       "      <td>221135570</td>\n",
       "      <td>current and former louisville, kentucky police...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2873506</td>\n",
       "      <td>1343758492847390721</td>\n",
       "      <td>892188990991876096</td>\n",
       "      <td>we must take our country back!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2218955</td>\n",
       "      <td>595090533464350720</td>\n",
       "      <td>101264587</td>\n",
       "      <td>report: isis using baltimore riots to recruit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2688385</td>\n",
       "      <td>186092654705115136</td>\n",
       "      <td>1429761</td>\n",
       "      <td>rt @ostrayvonmartin: naacp, civil rights leade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1951489</td>\n",
       "      <td>746785477554896896</td>\n",
       "      <td>205531045</td>\n",
       "      <td>tamir rice would have been 14 today. ❤️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1216863</td>\n",
       "      <td>951612072487456768</td>\n",
       "      <td>87957969</td>\n",
       "      <td>opinion | now can we call the president a whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1521814</td>\n",
       "      <td>1385383159848706052</td>\n",
       "      <td>2729784259</td>\n",
       "      <td>anyone trying to argue the merit of shooting a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                rt_id               rt_uid  \\\n",
       "0    327408   763915332431941632            347627434   \n",
       "1    426399  1275114784787247104             47839801   \n",
       "2   3544479  1284228067561558018   932630991298007041   \n",
       "3    838469  1311615252748996608             16041234   \n",
       "4   3229052  1656723610743222273             55060090   \n",
       "5   4331812   909880965475868672             22637974   \n",
       "6    723406  1670135823684059137             55330244   \n",
       "7    976267  1348348496018104322  1201348645225930752   \n",
       "8    507700  1399007405468532743            170254080   \n",
       "9   3705769   301531740466470912             14752085   \n",
       "10  3460922  1068750114712371200            437737633   \n",
       "11  2622734   441933742211203072            469194846   \n",
       "12  2462461  1299552420264112130           2941665345   \n",
       "13  1598089  1535032524870758402             27789999   \n",
       "14  4346423  1151177118329573376             42958829   \n",
       "15    64432   938558907475095552              2729061   \n",
       "16   184537   500738818493128704             89887215   \n",
       "17  3084287  1439587622406533120            624210678   \n",
       "18  1863171  1420679211354927104            328756439   \n",
       "19  3018550  1471347050952409089             15515169   \n",
       "20   429854  1298348675765329920            443350004   \n",
       "21  2616162  1565017812367773696   781982295863484456   \n",
       "22  2812065  1408469168547053573            285852662   \n",
       "23  3484304  1350107733907955713   787935427961446400   \n",
       "24   169251  1404959730620145682             21103426   \n",
       "25   445804  1505999197564141569   819034558058229760   \n",
       "26  2319892  1268364850822029325            252398355   \n",
       "27  3363394  1621263614849204226           3066800573   \n",
       "28  2808890  1374820817259831305             22650211   \n",
       "29  1427368  1067182446704242689             17494010   \n",
       "30   479053  1058084733899333633           4581356534   \n",
       "31  1355533  1001259369562947584           2937613910   \n",
       "32  3542265  1273035148498362368             16005250   \n",
       "33  1810619   537098798372507648             27075032   \n",
       "34  1242038  1293332620118577157  1079833198463467520   \n",
       "35   347071  1136059220325994496            270627293   \n",
       "36  1642891  1270037707834773504           2907975195   \n",
       "37  1529777  1529589638075142152  1270742738946846720   \n",
       "38  3768541  1579185007020871680             23169735   \n",
       "39  4123123   799030397380206592             45671898   \n",
       "40  1763758  1037754885805166594           2962527299   \n",
       "41  3556568  1399779255085527045             20545835   \n",
       "42  2537875  1380241583572934662  1331107444416770048   \n",
       "43  1666440  1555228206499766272            221135570   \n",
       "44  2873506  1343758492847390721   892188990991876096   \n",
       "45  2218955   595090533464350720            101264587   \n",
       "46  2688385   186092654705115136              1429761   \n",
       "47  1951489   746785477554896896            205531045   \n",
       "48  1216863   951612072487456768             87957969   \n",
       "49  1521814  1385383159848706052           2729784259   \n",
       "\n",
       "                                        modeling_text  \n",
       "0   so wrong\\nnfl denies dallas cowboys’ req to ho...  \n",
       "1   get in losers, we’re dismantling the patriarchy.   \n",
       "2             the us equity markets = absolute units   \n",
       "3   trump administration instructed law enforcemen...  \n",
       "4   mitt romney condemns trump for offering pardon...  \n",
       "5   yale joins list of universities replacing \"fre...  \n",
       "6   nova scotia police thwart 3 arson attacks as m...  \n",
       "7   the maga cult terrorists are vowing to return ...  \n",
       "8   after the “socialist”-branded no evil foods bu...  \n",
       "9   rt @michaelianblack: pay the people who write ...  \n",
       "10  always loved this george h.w. bush moment from...  \n",
       "11  'race card transaction successful': larry elde...  \n",
       "12  cops stop out-of-state caravan, arrest 9 heade...  \n",
       "13  methodist leaders say 'rebellion and dysfuncti...  \n",
       "14  pres. trump has refused to walk back his racis...  \n",
       "15  a free sf anthology about space travel, inequa...  \n",
       "16  nixon says he has signed a state of emergency ...  \n",
       "17  omg i just realized that all we need to do to ...  \n",
       "18  house gop leader kevin mccarthy is re-writing ...  \n",
       "19  breaking: nypd arresting unvaxxed diners at ap...  \n",
       "20  if you think critical race studies is a threat...  \n",
       "21  “one thing about black people is we don’t wait...  \n",
       "22  tamir rice would’ve been 19 years old today. t...  \n",
       "23  feds edge closer to sedition charge in #capito...  \n",
       "24  i have mixed feelings about making juneteenth ...  \n",
       "25  i barely saw any asians in the ncaa tournament...  \n",
       "26          the right to riot shall not be infringed.  \n",
       "27  scoop: florida state university has adopted a ...  \n",
       "28  sesame workshop, the organization behind \"sesa...  \n",
       "29  to celebrate this #cybermonday, it’s time we g...  \n",
       "30  i decided to #exit the democrat party. think f...  \n",
       "31  some “star” players are threatening to sit out...  \n",
       "32  this card was spotted at a supermarket in germ...  \n",
       "33  image: rt @russptacek: #ferguson:  store in fl...  \n",
       "34  economic laws are not subject to a vote. they ...  \n",
       "35  theydies and gentlethems:\\non this, the fourth...  \n",
       "36  gen z will drink one medium caramel latte, not...  \n",
       "37  .@prisonculture on the place of imagination an...  \n",
       "38  disgusting anti-black racist comments from loc...  \n",
       "39  actually said the answer to \"what happened\"? i...  \n",
       "40  gay culture is having to clarify the species o...  \n",
       "41  rep. nancy mace's home in charleston, s.c., wa...  \n",
       "42  🐾 we love dr. martin tobin. that’s all. that’s...  \n",
       "43  current and former louisville, kentucky police...  \n",
       "44                   we must take our country back!!   \n",
       "45  report: isis using baltimore riots to recruit ...  \n",
       "46  rt @ostrayvonmartin: naacp, civil rights leade...  \n",
       "47           tamir rice would have been 14 today. ❤️   \n",
       "48  opinion | now can we call the president a whit...  \n",
       "49  anyone trying to argue the merit of shooting a...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_blm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "642546e8-df5f-4b84-9301-53bf10b483f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data = pd.read_csv('/projects/academic/kjoseph/zijian/blm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6d2635-f7ac-43da-acc8-6d0e716555b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562d6e7e913e4f8d8f1f98be1362bf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 50 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc87465455b2498c9a198389b83c4538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='pos', style=ButtonStyle()), Button(description='neg', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f9c986c9b14a68859edae2741d2992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "annotations = Annotation.run_annotation(random_blm_data,labels,'modeling_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "049cc636-2a1b-4826-8771-819889ecbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data['label'] = annotations['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d40ebdb-f900-4ea9-921c-3968c87de136",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data = pd.read_csv('/projects/academic/kjoseph/zijian/negative_tweet_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb17140-a33d-453b-8d9c-c463ee895e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_ids = validate_data['rt_id'].tolist()\n",
    "rt_ids_str = ', '.join([str(id) for id in rt_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5a5775a-761e-4444-89e1-9f5f5d92bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {ori_table_name} WHERE rt_id IN ({rt_ids_str}) ORDER BY RAND() LIMIT 200;\"\n",
    "neg_vali = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7820e36-c726-45e6-814d-832441b6ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {ori_table_name} WHERE rt_id NOT IN ({rt_ids_str}) ORDER BY RAND() LIMIT 200;\"\n",
    "pos_vali = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7aa14fc-27fa-4c77-942d-3da67797c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_vali['label'] = 'neg'\n",
    "pos_vali['label'] = 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d975e401-2770-47ff-a41f-b0e7b829e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data_vali = pd.concat([neg_vali,pos_vali]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c693d8-d198-49ad-9ee8-e60663b2e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vali_per = 0.4\n",
    "# random_blm_data_vali = random_blm_data.groupby('label').apply(lambda x: x.sample(frac=vali_per, random_state=42)).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f52fd7b6-97d6-4b99-b841-d2bd7c7da16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(random_blm_data[random_blm_data['label'].isin(['neg','pos'])][['modeling_text','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d842b92-b3a4-4e00-846c-e389f510ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': dataset  # Set the 'train' split\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9243256f-8bd2-4202-9742-53a96c82f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['validation'] = Dataset.from_pandas(random_blm_data_vali[['modeling_text','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "134ea984-d3c5-4fbf-a258-f314f65cba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f4b1de5-d4bd-44bc-92aa-f70cedb08e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/academic/kjoseph/zijian/zijianan_'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "076e290a-cdff-436b-a2cd-f2ec51ef24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = save_path + \"blm_random_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c2ead9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43cae4f4-5401-474f-9e69-65573f994ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[WARNING|integration_utils.py:82] 2024-05-13 15:54:07,244 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2024 15:54:07 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 2distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[WARNING|modeling_utils.py:4172] 2024-05-13 15:54:11,151 >> Some weights of RobertaModel were not initialized from the model checkpoint at launch/POLITICS and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c8a932395f4a798fc1921a4722831e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/29 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92efb6a622934ecfad22f71c7e3f0796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf2ad7193264cd38a2c4442430f901f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6dbabe413942f8bca79d9cd974cd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ff0b71abe44aeda3bf6ae5ff382a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c43a807e1f4c7a97aa3164f3219512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/pytorch/1.13.1-CUDA-11.8.0/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "[WARNING|modeling_utils.py:1188] 2024-05-13 15:54:21,241 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =      4.015\n",
      "  train_runtime            = 0:00:04.97\n",
      "  train_samples            =         29\n",
      "  train_samples_per_second =     58.298\n",
      "  train_steps_per_second   =       2.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =     0.5475\n",
      "  eval_loss               =      5.442\n",
      "  eval_runtime            = 0:00:01.04\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    383.723\n",
      "  eval_steps_per_second   =      6.715\n",
      "{'eval_loss': 5.441959857940674, 'eval_accuracy': 0.5475, 'eval_runtime': 1.0424, 'eval_samples_per_second': 383.723, 'eval_steps_per_second': 6.715, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 54.8%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_instance = ModelTraining(dataset=dataset, \\\n",
    "                                  model_name_or_path='launch/POLITICS', \\\n",
    "                                  label_column_name='label', \\\n",
    "                                  text_column_name='modeling_text',\\\n",
    "                                  save_path=save_path, \\\n",
    "                                  num_train_epochs=10)\n",
    "model_0 = training_instance.train_model()\n",
    "model_0.to('cpu')\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553f28e-c538-41bf-90f2-a3baec76db0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d29ba8c-959d-4b8f-a13b-663be917ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query = f'''\n",
    "# SELECT * FROM {ori_table_name} ORDER BY RAND() LIMIT 1000;\n",
    "# '''\n",
    "# inference_data = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e06be579-e027-49bc-a81c-49c99fab628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = random_blm_data_vali.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a5d874c-83b5-4a0e-bcba-336c3cd55dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/projects/academic/kjoseph/zijian/zijianan_blm_random_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76bebc56-7bef-42ce-8ad6-e2546f5229de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3c056cabf54f058be86f881644e205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11ad668726e43b68a90daf916db8cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb548cfeeaf7446ab2cc37630141bd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44335ce0c7ad4e23972236d78d0e6fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339f67b175c1469ba2471b0d2d0fa989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-13 15:55:25,544 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n"
     ]
    }
   ],
   "source": [
    "active_learning_instance = ActiveLearning(model_name_or_path=save_path, \\\n",
    "                                  label_column_name='label', \\\n",
    "                                  text_column_name='modeling_text',\\\n",
    "                                  theta=10,\n",
    "                                  i=3,\n",
    "                                  vali_data=dataset[\"validation\"],\n",
    "                                  inference_datasets=inference_data,\n",
    "                                  tokenizer_name='roberta-large',\n",
    "                                  uname=uname,\n",
    "                                  labels=['neg','pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed202b1-13c6-46d4-a508-b9c194de02f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-13 15:55:29,468 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
      "Processing batches:  77%|███████▋  | 10/13 [00:04<00:01,  2.15it/s][WARNING|logging.py:329] 2024-05-13 15:55:34,123 >> You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Processing batches: 100%|██████████| 13/13 [00:05<00:00,  2.24it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d86fd0ca91b424e8a5410c953be5533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a3666540e64b2f892d549b34927673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='neg', style=ButtonStyle()), Button(description='pos', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb28dc7b9f54edea8b1f0819f700cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|integration_utils.py:82] 2024-05-13 15:55:38,008 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/13/2024 15:55:38 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 2distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7117ed390d35479b92c830511e2dd255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/10 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58d55a3acd44511b5ade80c4f71c579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce3238924984b169689ec77ccb8d09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027cbeb696f84bb0842f5b1733fa7dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6c2d423c574a849aaedbd9d807ff90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8312cb1fc834461dbabb8b26b3c6be66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/academic/kjoseph/zijian/pytorch/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/pytorch/1.13.1-CUDA-11.8.0/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "[WARNING|modeling_utils.py:1188] 2024-05-13 15:55:47,218 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     2.9936\n",
      "  train_runtime            = 0:00:02.08\n",
      "  train_samples            =         10\n",
      "  train_samples_per_second =     47.889\n",
      "  train_steps_per_second   =      4.789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =      0.505\n",
      "  eval_loss               =     5.1015\n",
      "  eval_runtime            = 0:00:00.94\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    421.282\n",
      "  eval_steps_per_second   =      7.372\n",
      "{'eval_loss': 5.1015143394470215, 'eval_accuracy': 0.505, 'eval_runtime': 0.9495, 'eval_samples_per_second': 421.282, 'eval_steps_per_second': 7.372, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 50.5%\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-13 15:55:53,260 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
      "Processing batches: 100%|██████████| 13/13 [00:05<00:00,  2.28it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e7fdf99b944a0db66a7d5bfe037010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffe373636c943318420617cb26d911c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='neg', style=ButtonStyle()), Button(description='pos', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0610ee8477114d049d3983cce5242e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = active_learning_instance.perform_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f558f-2474-4307-85d8-5e4e826cc860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
