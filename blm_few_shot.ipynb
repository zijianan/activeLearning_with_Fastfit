{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f8b6c9-c3b3-40e5-b867-30a6c85b3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from activeLearning_with_Fastfit.human_annotator_with_hint import MySQLDataHandler, Annotation, ModelTraining, ActiveLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c16efa-d1ab-4696-969a-16b7107b9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Features, Value,load_dataset,DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8dffe2-ae95-496a-8ec2-4b3db9ff394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7aa3a6-e358-4b2c-b5ac-bc40ba286d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "uname = 'zijianan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16f2332-fe47-4b71-a841-c9d57b76cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_table_name = 'blm_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e7775f-3293-4892-9b82-a3573be572c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_annotated_table_name = 'blm_annotated_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "974bba83-c682-436c-a866-14672ed16aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_handler = MySQLDataHandler('localhost', 'zijianan', '12Q3qeqs,', '5_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c58d38d-bca8-4d4e-aff9-677430be273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/data/blm_model/'+uname+'_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9fe5e2-aedc-45b7-bfc5-e5931c1f7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['pos','neg','unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1e191-2322-4bdd-ac79-764f65437aaa",
   "metadata": {},
   "source": [
    "### random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd0a267-8321-4fae-87e1-28eea6c20f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "SELECT * FROM {ori_table_name} ORDER BY RAND() LIMIT 50;\n",
    "'''\n",
    "random_blm_data = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a6e483-59b7-4c37-88d9-4f26806535d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rt_id</th>\n",
       "      <th>rt_uid</th>\n",
       "      <th>modeling_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2331411</td>\n",
       "      <td>1349188813525053440</td>\n",
       "      <td>24733117</td>\n",
       "      <td>manhunt intensifies as authorities warn some r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1565474</td>\n",
       "      <td>1131772627167662087</td>\n",
       "      <td>77646168</td>\n",
       "      <td>🔱#topmeme award goes to @irrepressably for thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2682674</td>\n",
       "      <td>1532197311262208000</td>\n",
       "      <td>3257608936</td>\n",
       "      <td>california released a 600-page reparations rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928334</td>\n",
       "      <td>1387712611203133440</td>\n",
       "      <td>21950364</td>\n",
       "      <td>how do you describe today’s republican party?\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2566734</td>\n",
       "      <td>872567663414747136</td>\n",
       "      <td>90480218</td>\n",
       "      <td>i'll be joining my friend @seanhannity tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>226289</td>\n",
       "      <td>1298460036587335680</td>\n",
       "      <td>16245840</td>\n",
       "      <td>melania is often described as useless but plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2598810</td>\n",
       "      <td>1305929584643387395</td>\n",
       "      <td>30699754</td>\n",
       "      <td>details on the settlement that the city of lou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3775959</td>\n",
       "      <td>504840215924846592</td>\n",
       "      <td>279390084</td>\n",
       "      <td>judicial system's blessing of police use of ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3082334</td>\n",
       "      <td>1405918348416847883</td>\n",
       "      <td>2482515498</td>\n",
       "      <td>this #juneteenth we must go beyond recognizing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1405982</td>\n",
       "      <td>570005217485426688</td>\n",
       "      <td>16967845</td>\n",
       "      <td>over 1 in 7 women, nearly 18 million, lived in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3841924</td>\n",
       "      <td>415254507640348672</td>\n",
       "      <td>427799256</td>\n",
       "      <td>research says: encouraging girls is key in clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1742560</td>\n",
       "      <td>519965171465203712</td>\n",
       "      <td>19542622</td>\n",
       "      <td>this is why people hate politics. rt @wltx: (a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3566560</td>\n",
       "      <td>1622716262223675408</td>\n",
       "      <td>6782762</td>\n",
       "      <td>in 100 years, if the woke have their way, peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1012054</td>\n",
       "      <td>929404074075631616</td>\n",
       "      <td>14894518</td>\n",
       "      <td>why we need a broad-based movement, like the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1476442</td>\n",
       "      <td>69992490010279936</td>\n",
       "      <td>7782542</td>\n",
       "      <td>wash post editorial bd calls for moratorium on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2342842</td>\n",
       "      <td>1523289879207366657</td>\n",
       "      <td>1917731</td>\n",
       "      <td>the possibility that the supreme court will ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2434042</td>\n",
       "      <td>917063260549124097</td>\n",
       "      <td>1687584320</td>\n",
       "      <td>if a girl tells you that you look like troye s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>253237</td>\n",
       "      <td>534866192922853377</td>\n",
       "      <td>16331010</td>\n",
       "      <td>floyd mayweather, twerk-aholic: 10 girls, 1 fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2208757</td>\n",
       "      <td>1564664547440484354</td>\n",
       "      <td>232901331</td>\n",
       "      <td>pa senate candidate outs himself as a total ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3759157</td>\n",
       "      <td>1391876635998277632</td>\n",
       "      <td>809115114</td>\n",
       "      <td>nyc transit authority president sarah feinberg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2446087</td>\n",
       "      <td>1110901274415906819</td>\n",
       "      <td>84734907</td>\n",
       "      <td>it's time to stop trump's discriminatory anti-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2849495</td>\n",
       "      <td>1049426150693457920</td>\n",
       "      <td>921107749471219712</td>\n",
       "      <td>ive been thinking abt this for three days \\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1563455</td>\n",
       "      <td>1088515741282754560</td>\n",
       "      <td>10252962</td>\n",
       "      <td>white supremacist pleads guilty to killing a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3370365</td>\n",
       "      <td>541495504186507264</td>\n",
       "      <td>14222536</td>\n",
       "      <td>bedtime! cant wait for tomorrow; cohosting the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2463297</td>\n",
       "      <td>1305224757202292737</td>\n",
       "      <td>329221989</td>\n",
       "      <td>fuck yo #bluelivesmatter shit.\\n\\ncops choose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2756097</td>\n",
       "      <td>193021197888389120</td>\n",
       "      <td>16348549</td>\n",
       "      <td>#dearg8 it is time to break the vicious cycle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3648897</td>\n",
       "      <td>816857467615383553</td>\n",
       "      <td>138190051</td>\n",
       "      <td>\"f— trump! f— white people!\"\\n\\n#blmkidnapping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4124097</td>\n",
       "      <td>828693960013049856</td>\n",
       "      <td>4327242015</td>\n",
       "      <td>breaking: donald trump will not be allowed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1243988</td>\n",
       "      <td>1305848846933778433</td>\n",
       "      <td>472987747</td>\n",
       "      <td>there are bad takes, and then there are danger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>979937</td>\n",
       "      <td>1384298204783542273</td>\n",
       "      <td>907139600</td>\n",
       "      <td>this is one of the most beautiful, sad photos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3524100</td>\n",
       "      <td>1002014859213656065</td>\n",
       "      <td>711026018048286722</td>\n",
       "      <td>since roseanne took ambien and was racist, i j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>772519</td>\n",
       "      <td>1331007116971130881</td>\n",
       "      <td>14177942</td>\n",
       "      <td>ending violence against women is everyone’s bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3627379</td>\n",
       "      <td>1459233134109765633</td>\n",
       "      <td>299896657</td>\n",
       "      <td>less than 24 hours after joe biden said the wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3167727</td>\n",
       "      <td>584033486958370816</td>\n",
       "      <td>315833613</td>\n",
       "      <td>gay tip: invest in sexy underwear. it helps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1579199</td>\n",
       "      <td>1286729620893700098</td>\n",
       "      <td>15369276</td>\n",
       "      <td>.@slcmayor erin mendenhall is looking into fiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3494399</td>\n",
       "      <td>1498855657675628551</td>\n",
       "      <td>1392282998</td>\n",
       "      <td>“to our younger transgender americans, i will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3994898</td>\n",
       "      <td>947101098975940608</td>\n",
       "      <td>28785486</td>\n",
       "      <td>los angeles police said they have arrested a 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2760884</td>\n",
       "      <td>547569216157913088</td>\n",
       "      <td>15864446</td>\n",
       "      <td>nyc landmarks to dim lights for slain nypd off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3743906</td>\n",
       "      <td>1269758561720156160</td>\n",
       "      <td>50055701</td>\n",
       "      <td>black lives matter.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4054878</td>\n",
       "      <td>784200319622258688</td>\n",
       "      <td>20058011</td>\n",
       "      <td>ask the candidates how they would lift working...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4328478</td>\n",
       "      <td>84467466264260608</td>\n",
       "      <td>22056192</td>\n",
       "      <td>rt @danrothschild: i assume since it's now the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3169196</td>\n",
       "      <td>636435604822077440</td>\n",
       "      <td>18014620</td>\n",
       "      <td>donald trump has already said so much racist s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3989036</td>\n",
       "      <td>839893470470889473</td>\n",
       "      <td>17023380</td>\n",
       "      <td>my favorite facial expression is when you hold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2213224</td>\n",
       "      <td>223617994742448130</td>\n",
       "      <td>465763204</td>\n",
       "      <td>gay marriage is legal in 6 states, but having ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1995285</td>\n",
       "      <td>1382082435278647301</td>\n",
       "      <td>984500402350641152</td>\n",
       "      <td>teachers are “local government workers”. we do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3576432</td>\n",
       "      <td>654802199021654016</td>\n",
       "      <td>14717197</td>\n",
       "      <td>wilmore: shouldn't dismiss #demdebate as \"bori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>926068</td>\n",
       "      <td>1678367877899091968</td>\n",
       "      <td>1001663707045421058</td>\n",
       "      <td>⚠️woke content⚠️\\n\\n🧵school integration was ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1456033</td>\n",
       "      <td>1405929145477992450</td>\n",
       "      <td>50735431</td>\n",
       "      <td>juneteenth holiday marking the end of slavery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3999344</td>\n",
       "      <td>1011737013958029313</td>\n",
       "      <td>226194552</td>\n",
       "      <td>by muddying the waters, you are destroying the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2353527</td>\n",
       "      <td>542437661433012225</td>\n",
       "      <td>123478177</td>\n",
       "      <td>we don't have to choose between affordable hou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                rt_id               rt_uid  \\\n",
       "0   2331411  1349188813525053440             24733117   \n",
       "1   1565474  1131772627167662087             77646168   \n",
       "2   2682674  1532197311262208000           3257608936   \n",
       "3   1928334  1387712611203133440             21950364   \n",
       "4   2566734   872567663414747136             90480218   \n",
       "5    226289  1298460036587335680             16245840   \n",
       "6   2598810  1305929584643387395             30699754   \n",
       "7   3775959   504840215924846592            279390084   \n",
       "8   3082334  1405918348416847883           2482515498   \n",
       "9   1405982   570005217485426688             16967845   \n",
       "10  3841924   415254507640348672            427799256   \n",
       "11  1742560   519965171465203712             19542622   \n",
       "12  3566560  1622716262223675408              6782762   \n",
       "13  1012054   929404074075631616             14894518   \n",
       "14  1476442    69992490010279936              7782542   \n",
       "15  2342842  1523289879207366657              1917731   \n",
       "16  2434042   917063260549124097           1687584320   \n",
       "17   253237   534866192922853377             16331010   \n",
       "18  2208757  1564664547440484354            232901331   \n",
       "19  3759157  1391876635998277632            809115114   \n",
       "20  2446087  1110901274415906819             84734907   \n",
       "21  2849495  1049426150693457920   921107749471219712   \n",
       "22  1563455  1088515741282754560             10252962   \n",
       "23  3370365   541495504186507264             14222536   \n",
       "24  2463297  1305224757202292737            329221989   \n",
       "25  2756097   193021197888389120             16348549   \n",
       "26  3648897   816857467615383553            138190051   \n",
       "27  4124097   828693960013049856           4327242015   \n",
       "28  1243988  1305848846933778433            472987747   \n",
       "29   979937  1384298204783542273            907139600   \n",
       "30  3524100  1002014859213656065   711026018048286722   \n",
       "31   772519  1331007116971130881             14177942   \n",
       "32  3627379  1459233134109765633            299896657   \n",
       "33  3167727   584033486958370816            315833613   \n",
       "34  1579199  1286729620893700098             15369276   \n",
       "35  3494399  1498855657675628551           1392282998   \n",
       "36  3994898   947101098975940608             28785486   \n",
       "37  2760884   547569216157913088             15864446   \n",
       "38  3743906  1269758561720156160             50055701   \n",
       "39  4054878   784200319622258688             20058011   \n",
       "40  4328478    84467466264260608             22056192   \n",
       "41  3169196   636435604822077440             18014620   \n",
       "42  3989036   839893470470889473             17023380   \n",
       "43  2213224   223617994742448130            465763204   \n",
       "44  1995285  1382082435278647301   984500402350641152   \n",
       "45  3576432   654802199021654016             14717197   \n",
       "46   926068  1678367877899091968  1001663707045421058   \n",
       "47  1456033  1405929145477992450             50735431   \n",
       "48  3999344  1011737013958029313            226194552   \n",
       "49  2353527   542437661433012225            123478177   \n",
       "\n",
       "                                        modeling_text  \n",
       "0   manhunt intensifies as authorities warn some r...  \n",
       "1   🔱#topmeme award goes to @irrepressably for thi...  \n",
       "2   california released a 600-page reparations rep...  \n",
       "3   how do you describe today’s republican party?\\...  \n",
       "4   i'll be joining my friend @seanhannity tonight...  \n",
       "5   melania is often described as useless but plea...  \n",
       "6   details on the settlement that the city of lou...  \n",
       "7   judicial system's blessing of police use of ex...  \n",
       "8   this #juneteenth we must go beyond recognizing...  \n",
       "9   over 1 in 7 women, nearly 18 million, lived in...  \n",
       "10  research says: encouraging girls is key in clo...  \n",
       "11  this is why people hate politics. rt @wltx: (a...  \n",
       "12  in 100 years, if the woke have their way, peop...  \n",
       "13  why we need a broad-based movement, like the w...  \n",
       "14  wash post editorial bd calls for moratorium on...  \n",
       "15  the possibility that the supreme court will ov...  \n",
       "16  if a girl tells you that you look like troye s...  \n",
       "17  floyd mayweather, twerk-aholic: 10 girls, 1 fl...  \n",
       "18  pa senate candidate outs himself as a total ra...  \n",
       "19  nyc transit authority president sarah feinberg...  \n",
       "20  it's time to stop trump's discriminatory anti-...  \n",
       "21  ive been thinking abt this for three days \\n\\n...  \n",
       "22  white supremacist pleads guilty to killing a b...  \n",
       "23  bedtime! cant wait for tomorrow; cohosting the...  \n",
       "24  fuck yo #bluelivesmatter shit.\\n\\ncops choose ...  \n",
       "25  #dearg8 it is time to break the vicious cycle ...  \n",
       "26  \"f— trump! f— white people!\"\\n\\n#blmkidnapping...  \n",
       "27  breaking: donald trump will not be allowed to ...  \n",
       "28  there are bad takes, and then there are danger...  \n",
       "29  this is one of the most beautiful, sad photos ...  \n",
       "30  since roseanne took ambien and was racist, i j...  \n",
       "31  ending violence against women is everyone’s bu...  \n",
       "32  less than 24 hours after joe biden said the wo...  \n",
       "33       gay tip: invest in sexy underwear. it helps.  \n",
       "34  .@slcmayor erin mendenhall is looking into fiv...  \n",
       "35  “to our younger transgender americans, i will ...  \n",
       "36  los angeles police said they have arrested a 2...  \n",
       "37  nyc landmarks to dim lights for slain nypd off...  \n",
       "38                               black lives matter.   \n",
       "39  ask the candidates how they would lift working...  \n",
       "40  rt @danrothschild: i assume since it's now the...  \n",
       "41  donald trump has already said so much racist s...  \n",
       "42  my favorite facial expression is when you hold...  \n",
       "43  gay marriage is legal in 6 states, but having ...  \n",
       "44  teachers are “local government workers”. we do...  \n",
       "45  wilmore: shouldn't dismiss #demdebate as \"bori...  \n",
       "46  ⚠️woke content⚠️\\n\\n🧵school integration was ne...  \n",
       "47  juneteenth holiday marking the end of slavery ...  \n",
       "48  by muddying the waters, you are destroying the...  \n",
       "49  we don't have to choose between affordable hou...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_blm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba6d2635-f7ac-43da-acc8-6d0e716555b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e579d21a3b4266b2cea151d5c66dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 50 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1164119d734cefbeda4aed56975927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='pos', style=ButtonStyle()), Button(description='neg', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7173affeea824908a3729ecd0fb6635b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "annotations = Annotation.run_annotation(random_blm_data,labels,'modeling_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "049cc636-2a1b-4826-8771-819889ecbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data['label'] = annotations['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b962efe-9af6-4117-9185-378106b8cb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "642546e8-df5f-4b84-9301-53bf10b483f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data = pd.read_csv('blm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d40ebdb-f900-4ea9-921c-3968c87de136",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data = pd.read_csv('/data/zijian/negative_tweet_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb17140-a33d-453b-8d9c-c463ee895e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_ids = validate_data['rt_id'].tolist()\n",
    "rt_ids_str = ', '.join([str(id) for id in rt_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5a5775a-761e-4444-89e1-9f5f5d92bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {ori_table_name} WHERE rt_id IN ({rt_ids_str}) ORDER BY RAND() LIMIT 200;\"\n",
    "neg_vali = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7820e36-c726-45e6-814d-832441b6ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {ori_table_name} WHERE rt_id NOT IN ({rt_ids_str}) ORDER BY RAND() LIMIT 200;\"\n",
    "pos_vali = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7aa14fc-27fa-4c77-942d-3da67797c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_vali['label'] = 'neg'\n",
    "pos_vali['label'] = 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d975e401-2770-47ff-a41f-b0e7b829e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_blm_data_vali = pd.concat([neg_vali,pos_vali]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c693d8-d198-49ad-9ee8-e60663b2e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vali_per = 0.4\n",
    "# random_blm_data_vali = random_blm_data.groupby('label').apply(lambda x: x.sample(frac=vali_per, random_state=42)).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f52fd7b6-97d6-4b99-b841-d2bd7c7da16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(random_blm_data[random_blm_data['label'].isin(['neg','pos'])][['modeling_text','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d842b92-b3a4-4e00-846c-e389f510ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': dataset  # Set the 'train' split\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9243256f-8bd2-4202-9742-53a96c82f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['validation'] = Dataset.from_pandas(random_blm_data_vali[['modeling_text','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "134ea984-d3c5-4fbf-a258-f314f65cba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test\"] = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f4b1de5-d4bd-44bc-92aa-f70cedb08e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/blm_model/zijianan_'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "076e290a-cdff-436b-a2cd-f2ec51ef24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = save_path + \"blm_random_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43cae4f4-5401-474f-9e69-65573f994ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:50:30 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:4172] 2024-05-08 10:50:31,529 >> Some weights of RobertaModel were not initialized from the model checkpoint at launch/POLITICS and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae168c8c69754d3b848108192acb2461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/29 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71f8257630b4d84b68126ae72ff6eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caa04fc33be4cb5a3ed07791facd731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93077cd1d5246fcbd2bd86333631ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e631408d1c464aac827856b2a724ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a3fce0afc4469c847b81cdbabbf6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zijianan/miniconda3/envs/fu/lib/python3.9/site-packages/fastfit/train.py:878: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(self.data_args.metric_name)\n",
      "/home/zijianan/miniconda3/envs/fu/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:50:39 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:50:41 - ERROR - wandb.jupyter - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzijianan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/zijianan/wandb/run-20240508_105042-qqjodq62</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zijianan/huggingface/runs/qqjodq62/workspace' target=\"_blank\">northern-terrain-40</a></strong> to <a href='https://wandb.ai/zijianan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zijianan/huggingface' target=\"_blank\">https://wandb.ai/zijianan/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zijianan/huggingface/runs/qqjodq62/workspace' target=\"_blank\">https://wandb.ai/zijianan/huggingface/runs/qqjodq62/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|modeling_utils.py:1188] 2024-05-08 10:50:53,246 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     3.9178\n",
      "  train_runtime            = 0:00:14.57\n",
      "  train_samples            =         29\n",
      "  train_samples_per_second =     19.904\n",
      "  train_steps_per_second   =      1.373\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =     0.5325\n",
      "  eval_loss               =     5.9804\n",
      "  eval_runtime            = 0:00:00.82\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    486.078\n",
      "  eval_steps_per_second   =     15.798\n",
      "{'eval_loss': 5.980385780334473, 'eval_accuracy': 0.5325, 'eval_runtime': 0.8229, 'eval_samples_per_second': 486.078, 'eval_steps_per_second': 15.798, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 53.2%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_instance = ModelTraining(dataset=dataset, \\\n",
    "                                  model_name_or_path='launch/POLITICS', \\\n",
    "                                  label_column_name='label', \\\n",
    "                                  text_column_name='modeling_text',\\\n",
    "                                  save_path=save_path, \\\n",
    "                                  num_train_epochs=10)\n",
    "model_0 = training_instance.train_model()\n",
    "model_0.to('cpu')\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553f28e-c538-41bf-90f2-a3baec76db0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d29ba8c-959d-4b8f-a13b-663be917ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query = f'''\n",
    "# SELECT * FROM {ori_table_name} ORDER BY RAND() LIMIT 1000;\n",
    "# '''\n",
    "# inference_data = db_handler.fetch_data(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e06be579-e027-49bc-a81c-49c99fab628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = random_blm_data_vali.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a5d874c-83b5-4a0e-bcba-336c3cd55dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/data/blm_model/zijianan_blm_random_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76bebc56-7bef-42ce-8ad6-e2546f5229de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-08 11:15:55,104 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n"
     ]
    }
   ],
   "source": [
    "active_learning_instance = ActiveLearning(model_name_or_path=save_path, \\\n",
    "                                  label_column_name='label', \\\n",
    "                                  text_column_name='modeling_text',\\\n",
    "                                  theta=10,\n",
    "                                  i=3,\n",
    "                                  vali_data=dataset[\"validation\"],\n",
    "                                  inference_datasets=inference_data,\n",
    "                                  tokenizer_name='roberta-large',\n",
    "                                  uname=uname,\n",
    "                                  labels=['neg','pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ed202b1-13c6-46d4-a508-b9c194de02f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-08 10:51:32,917 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
      "Processing batches:  77%|███████▋  | 10/13 [00:06<00:01,  1.66it/s][WARNING|logging.py:329] 2024-05-08 10:51:38,974 >> You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Processing batches: 100%|██████████| 13/13 [00:07<00:00,  1.72it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0281916af9cf4b3bb83c7dbfc9e20e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e1433fb06649488f5c923cd96289d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='neg', style=ButtonStyle()), Button(description='pos', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cb59bd17e54261b7c04c7459ca59c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:51:52 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87b6cd99d90490aaa9bb4db12a3362a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/10 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca30d621e8ff43c3aaf0b2e92c6af495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff88e3244df74fb1ae0a629a3e87ee7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dab780edbea401baf3ca542a5a7c4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edcd4fdc2834ef8b28487d9369371cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef865a0b600744c8ba6ec72899264476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:52:01 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zijianan/miniconda3/envs/fu/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[WARNING|modeling_utils.py:1188] 2024-05-08 10:52:02,399 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     3.5136\n",
      "  train_runtime            = 0:00:01.40\n",
      "  train_samples            =         10\n",
      "  train_samples_per_second =     71.229\n",
      "  train_steps_per_second   =      7.123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =      0.535\n",
      "  eval_loss               =     5.8452\n",
      "  eval_runtime            = 0:00:00.77\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    516.537\n",
      "  eval_steps_per_second   =     16.787\n",
      "{'eval_loss': 5.845210075378418, 'eval_accuracy': 0.535, 'eval_runtime': 0.7744, 'eval_samples_per_second': 516.537, 'eval_steps_per_second': 16.787, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 53.5%\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-08 10:52:07,258 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
      "Processing batches: 100%|██████████| 13/13 [00:07<00:00,  1.73it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d880c2592343359abde972f976966d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f762ddbc424cdb97d5d0ad42400a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='neg', style=ButtonStyle()), Button(description='pos', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e8c19dd5a5450488cc78174ad2fc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:52:21 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5f138271414d1394910036f8596fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/10 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f92ae877bd4b82bb4071b49ce97ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f3c360bd084bc7b8f59946d6a6cec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6abb3445ad45708d50b030d3225c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd17face2bc46eda559e43f6dd89683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604ad4cdb08b4c1e935ffd370e234515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:52:31 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zijianan/miniconda3/envs/fu/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[WARNING|modeling_utils.py:1188] 2024-05-08 10:52:31,701 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     3.2465\n",
      "  train_runtime            = 0:00:01.45\n",
      "  train_samples            =         10\n",
      "  train_samples_per_second =     68.526\n",
      "  train_steps_per_second   =      6.853\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =     0.5375\n",
      "  eval_loss               =     6.5403\n",
      "  eval_runtime            = 0:00:00.82\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    485.543\n",
      "  eval_steps_per_second   =      15.78\n",
      "{'eval_loss': 6.540343761444092, 'eval_accuracy': 0.5375, 'eval_runtime': 0.8238, 'eval_samples_per_second': 485.543, 'eval_steps_per_second': 15.78, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 53.8%\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR|base.py:1089] 2024-05-08 10:52:36,624 >> The model 'FastFit' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
      "Processing batches: 100%|██████████| 13/13 [00:07<00:00,  1.72it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a66ae25159401c9da99686a7c2d26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3c70374646469bba73a96fb30602db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='neg', style=ButtonStyle()), Button(description='pos', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc3854d7623464fae853b54fc9122d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:52:50 - WARNING - fastfit.train - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f514bb0b98416da42d5b80b672c353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/10 [00:00<?, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec20215a0b3465cadc677d17a50897c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db9986dbe614b928342db4a909c1331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset to infer max length for both query and document:   0%|          | 0/400 [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d414b2ce991c4b399b7d0865648f6e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c18e726558481494592fcf9c6e2db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea0e714caef407a9d0b670db956ed2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/08/2024 10:53:00 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zijianan/miniconda3/envs/fu/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[WARNING|modeling_utils.py:1188] 2024-05-08 10:53:00,728 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     3.4587\n",
      "  train_runtime            = 0:00:01.39\n",
      "  train_samples            =         10\n",
      "  train_samples_per_second =     71.442\n",
      "  train_steps_per_second   =      7.144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =       10.0\n",
      "  eval_accuracy           =     0.5275\n",
      "  eval_loss               =     6.5381\n",
      "  eval_runtime            = 0:00:00.80\n",
      "  eval_samples            =        400\n",
      "  eval_samples_per_second =    496.641\n",
      "  eval_steps_per_second   =     16.141\n",
      "{'eval_loss': 6.5380859375, 'eval_accuracy': 0.5275, 'eval_runtime': 0.8054, 'eval_samples_per_second': 496.641, 'eval_steps_per_second': 16.141, 'epoch': 10.0, 'eval_samples': 400}\n",
      "Accuracy: 52.8%\n"
     ]
    }
   ],
   "source": [
    "t1 = active_learning_instance.perform_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f558f-2474-4307-85d8-5e4e826cc860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fu",
   "language": "python",
   "name": "fu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
